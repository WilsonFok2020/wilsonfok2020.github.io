<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Learning object detection part 1 - why object detection matters | Wilson Fok</title> <meta name="generator" content="Jekyll v3.9.3" /> <meta property="og:title" content="Learning object detection part 1 - why object detection matters" /> <meta name="author" content="Wilson Fok" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Background This article is about how I acquaint myself with object detection methods and their models. Let’s begin by explaining why I am interested in object detection. Object detection problem is interesting because if we can detect objects of interest accurately, we can then count items, classify them, work out their spatial interaction or relationship and do much more. Unlike a classification task which aims to identify the most prominent or relevant object in an image, we are interested in knowing which, how many and where all objects are in an image or a video. Object detection is a much broader problem. Unlike a segmentation task which aims to assign each pixel in an image predefined classes, we are only interested in the whereabout or the vicinity of an object without concerning details at pixel level. Some computer vision tasks may not need to go down to the pixel level, including head counting, identifying the presence or absence of an objects, and so on. The need to detect an object or many objects in a scene is nothing new. However, the most exciting fact is that we can improve object detection performance by adapting convolutional neural network architecture which has proven to be suitable in image classification, natural language processing, computer vision, audio processing and more. Approaches My reading suggests that there are two main schools of thoughts. The first approach is a two-stage system, involving two separate models. The first model scans an image and then provides a basket of region candidates that likely contain an object of interests (region proposal stage). The second model can then do less work by taking in only these proposals and try to classify them. The famous member from this school is the R-CNN family. However, one of the main drawbacks of the two-stage system is its inefficiency in deployment as well as training. Two separate models are trained in series and both are needed during deployment, thereby making end-to-end training impossible. The second approach, by and large, tries to address this inefficiency. It advocates a single model that scans an image, estimates a pool of possible object locations and then classifies them. In this way, this model can be trained end-to-end, optimizing the complementary tasks simultaneously. For a long time, the two-stage approach yields better performance than a single-model approach. Until fairly recently, scientists have worked out a number of tricks that enables a single model to supersede two-stage models. Famous members include YOLO family, SSD, RetinaNet, etc. {width=10%} Network performance comparison on a public dataset (COCO). Source: EfficientDet: Scalable and Efficient Object Detection Furthermore, within this one-stage approach, we have seen two variants, namely anchor-based and anchor-free. The anchor-based approach relies on anchor boxes that are pre-determined and covered the entire image. Because they can be controlled via their aspect ratios and scales, these boxes capture object of various sizes and shapes. In much of the same way as region proposals, these anchor boxes serve the same purpose, but since they are set inside the model architecture, the model must go through and evaluate them all to detect any object of various shapes and sizes. This can be very useful if we have a rough idea on the kind of shapes and sizes of our objects of interest. Anchor boxes and how they work. Source: Anchor Boxes for Object Detection - MATLAB &amp; Simulink The anchor-free approach is closer conceptually to segmentation than anchor-based approach. Instead of relying on pre-defined anchor boxes as region candidates, anchor-free seeks to identify pixels that are useful for defining an object boundary. Since it operates on pixel level, it bears resemblance to segmentation tasks. For instance, to obtain object boundaries, cornerNet uses the corners while FCOS uses the center-of-mass. The upper left and lower right corners are detected by cornerNet. Source: CornerNet: Detecting Objects as Paired Keypoints The center of mass of the child is detected. Source: FCOS: Fully Convolutional One-Stage Object Detection Modern object detection methods involve the following elements: Anchor boxes Feature pyramid network Focal loss Non-max suppression How these elements play out in the network architecture and during training will be delineated when we go through my python source code in the latter parts of this object detection series." /> <meta property="og:description" content="Background This article is about how I acquaint myself with object detection methods and their models. Let’s begin by explaining why I am interested in object detection. Object detection problem is interesting because if we can detect objects of interest accurately, we can then count items, classify them, work out their spatial interaction or relationship and do much more. Unlike a classification task which aims to identify the most prominent or relevant object in an image, we are interested in knowing which, how many and where all objects are in an image or a video. Object detection is a much broader problem. Unlike a segmentation task which aims to assign each pixel in an image predefined classes, we are only interested in the whereabout or the vicinity of an object without concerning details at pixel level. Some computer vision tasks may not need to go down to the pixel level, including head counting, identifying the presence or absence of an objects, and so on. The need to detect an object or many objects in a scene is nothing new. However, the most exciting fact is that we can improve object detection performance by adapting convolutional neural network architecture which has proven to be suitable in image classification, natural language processing, computer vision, audio processing and more. Approaches My reading suggests that there are two main schools of thoughts. The first approach is a two-stage system, involving two separate models. The first model scans an image and then provides a basket of region candidates that likely contain an object of interests (region proposal stage). The second model can then do less work by taking in only these proposals and try to classify them. The famous member from this school is the R-CNN family. However, one of the main drawbacks of the two-stage system is its inefficiency in deployment as well as training. Two separate models are trained in series and both are needed during deployment, thereby making end-to-end training impossible. The second approach, by and large, tries to address this inefficiency. It advocates a single model that scans an image, estimates a pool of possible object locations and then classifies them. In this way, this model can be trained end-to-end, optimizing the complementary tasks simultaneously. For a long time, the two-stage approach yields better performance than a single-model approach. Until fairly recently, scientists have worked out a number of tricks that enables a single model to supersede two-stage models. Famous members include YOLO family, SSD, RetinaNet, etc. {width=10%} Network performance comparison on a public dataset (COCO). Source: EfficientDet: Scalable and Efficient Object Detection Furthermore, within this one-stage approach, we have seen two variants, namely anchor-based and anchor-free. The anchor-based approach relies on anchor boxes that are pre-determined and covered the entire image. Because they can be controlled via their aspect ratios and scales, these boxes capture object of various sizes and shapes. In much of the same way as region proposals, these anchor boxes serve the same purpose, but since they are set inside the model architecture, the model must go through and evaluate them all to detect any object of various shapes and sizes. This can be very useful if we have a rough idea on the kind of shapes and sizes of our objects of interest. Anchor boxes and how they work. Source: Anchor Boxes for Object Detection - MATLAB &amp; Simulink The anchor-free approach is closer conceptually to segmentation than anchor-based approach. Instead of relying on pre-defined anchor boxes as region candidates, anchor-free seeks to identify pixels that are useful for defining an object boundary. Since it operates on pixel level, it bears resemblance to segmentation tasks. For instance, to obtain object boundaries, cornerNet uses the corners while FCOS uses the center-of-mass. The upper left and lower right corners are detected by cornerNet. Source: CornerNet: Detecting Objects as Paired Keypoints The center of mass of the child is detected. Source: FCOS: Fully Convolutional One-Stage Object Detection Modern object detection methods involve the following elements: Anchor boxes Feature pyramid network Focal loss Non-max suppression How these elements play out in the network architecture and during training will be delineated when we go through my python source code in the latter parts of this object detection series." /> <link rel="canonical" href="/deep_learning/2020/07/31/Learning_Object_Detection_part1/" /> <meta property="og:url" content="/deep_learning/2020/07/31/Learning_Object_Detection_part1/" /> <meta property="og:site_name" content="Wilson Fok" /> <meta property="og:image" content="/assets/images/toy/cornerNet.png" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2020-07-31T00:00:00+08:00" /> <meta name="twitter:card" content="summary_large_image" /> <meta property="twitter:image" content="/assets/images/toy/cornerNet.png" /> <meta property="twitter:title" content="Learning object detection part 1 - why object detection matters" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Wilson Fok"},"dateModified":"2020-07-31T00:00:00+08:00","datePublished":"2020-07-31T00:00:00+08:00","description":"Background This article is about how I acquaint myself with object detection methods and their models. Let’s begin by explaining why I am interested in object detection. Object detection problem is interesting because if we can detect objects of interest accurately, we can then count items, classify them, work out their spatial interaction or relationship and do much more. Unlike a classification task which aims to identify the most prominent or relevant object in an image, we are interested in knowing which, how many and where all objects are in an image or a video. Object detection is a much broader problem. Unlike a segmentation task which aims to assign each pixel in an image predefined classes, we are only interested in the whereabout or the vicinity of an object without concerning details at pixel level. Some computer vision tasks may not need to go down to the pixel level, including head counting, identifying the presence or absence of an objects, and so on. The need to detect an object or many objects in a scene is nothing new. However, the most exciting fact is that we can improve object detection performance by adapting convolutional neural network architecture which has proven to be suitable in image classification, natural language processing, computer vision, audio processing and more. Approaches My reading suggests that there are two main schools of thoughts. The first approach is a two-stage system, involving two separate models. The first model scans an image and then provides a basket of region candidates that likely contain an object of interests (region proposal stage). The second model can then do less work by taking in only these proposals and try to classify them. The famous member from this school is the R-CNN family. However, one of the main drawbacks of the two-stage system is its inefficiency in deployment as well as training. Two separate models are trained in series and both are needed during deployment, thereby making end-to-end training impossible. The second approach, by and large, tries to address this inefficiency. It advocates a single model that scans an image, estimates a pool of possible object locations and then classifies them. In this way, this model can be trained end-to-end, optimizing the complementary tasks simultaneously. For a long time, the two-stage approach yields better performance than a single-model approach. Until fairly recently, scientists have worked out a number of tricks that enables a single model to supersede two-stage models. Famous members include YOLO family, SSD, RetinaNet, etc. {width=10%} Network performance comparison on a public dataset (COCO). Source: EfficientDet: Scalable and Efficient Object Detection Furthermore, within this one-stage approach, we have seen two variants, namely anchor-based and anchor-free. The anchor-based approach relies on anchor boxes that are pre-determined and covered the entire image. Because they can be controlled via their aspect ratios and scales, these boxes capture object of various sizes and shapes. In much of the same way as region proposals, these anchor boxes serve the same purpose, but since they are set inside the model architecture, the model must go through and evaluate them all to detect any object of various shapes and sizes. This can be very useful if we have a rough idea on the kind of shapes and sizes of our objects of interest. Anchor boxes and how they work. Source: Anchor Boxes for Object Detection - MATLAB &amp; Simulink The anchor-free approach is closer conceptually to segmentation than anchor-based approach. Instead of relying on pre-defined anchor boxes as region candidates, anchor-free seeks to identify pixels that are useful for defining an object boundary. Since it operates on pixel level, it bears resemblance to segmentation tasks. For instance, to obtain object boundaries, cornerNet uses the corners while FCOS uses the center-of-mass. The upper left and lower right corners are detected by cornerNet. Source: CornerNet: Detecting Objects as Paired Keypoints The center of mass of the child is detected. Source: FCOS: Fully Convolutional One-Stage Object Detection Modern object detection methods involve the following elements: Anchor boxes Feature pyramid network Focal loss Non-max suppression How these elements play out in the network architecture and during training will be delineated when we go through my python source code in the latter parts of this object detection series.","headline":"Learning object detection part 1 - why object detection matters","image":"/assets/images/toy/cornerNet.png","mainEntityOfPage":{"@type":"WebPage","@id":"/deep_learning/2020/07/31/Learning_Object_Detection_part1/"},"url":"/deep_learning/2020/07/31/Learning_Object_Detection_part1/"}</script> <!-- End Jekyll SEO tag --> <title>Wilson Fok - A data science enthusiast</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Learning object detection part 1 - why object detection matters" /> <meta name="keywords" content="Learning object detection part 1 - why object detection matters, Wilson Fok, Deep_Learning" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Wilson Fok" property="og:site_name"> <meta content="Learning object detection part 1 - why object detection matters" property="og:title"> <meta content="article" property="og:type"> <meta content="A brief introduction to object detection" property="og:description"> <meta content="/deep_learning/2020/07/31/Learning_Object_Detection_part1/" property="og:url"> <meta content="2020-07-31T00:00:00+08:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="/assets/img/posts//assets/images/toy/cornerNet.png" property="og:image"> <meta content="Deep_Learning" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="Learning object detection part 1 - why object detection matters"> <meta content="Wilson Fok" property="og:site_name"> <meta name="twitter:url" content="/deep_learning/2020/07/31/Learning_Object_Detection_part1/"> <meta name="twitter:description" content="Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. I also like to make new friends and connections. Let's connect! "> <!-- load layout style css --> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <!-- one or more of the below scripts does fancy word animation and dropdown menu --> <script src="/assets/extra_js/jquery-3.4.1.min.js"></script> <script src="/assets/extra_js/picturefill min/picturefill.min.js"></script> <script src="/assets/extra_js/instantsearch min/instantsearch.min.js"></script> <script src="/assets/extra_js/moment min/moment.min.js"></script> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </head><body> <div class="container-fluid"><header> <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script> <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css"> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Wilson Fok</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Wilson Fok</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog/categories">Categories</a> </li> <li class="nav-item"> <a class="nav-link" href="/gallery">Gallery</a> </li> <li class="nav-item"> <a class="nav-link" href="/contact">Contact Me</a> </li> </ul> </div> <ul class="nav justify-content-end"> <!-- <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> --> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/deep_learning/2020/07/31/Learning_Object_Detection_part1/">Learning object detection part 1 - why object detection matters</a></li> </ol> </nav> </div><div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <h1 class="post-title" itemprop="name headline">Learning object detection part 1 - why object detection matters</h1> <p></p> <h6 class="post-meta"> <i> Summary : A brief introduction to object detection</i> </h6> <p class="post-summary">Posted by : <img src="/assets/img/profile.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Wilson Fok</span> </span> on <time datetime="2020-07-31 00:00:00 +0800" itemprop="datePublished">Jul 31, 2020</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/deep_learning/2020/07/31/Learning_Object_Detection_part1/"></span> <div class="post-categories"> Category : <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </div> </div> <div class="card-body" itemprop="articleBody"> <h3 id="background">Background</h3> <p>This article is about how I acquaint myself with object detection methods and their models. Let’s begin by explaining why I am interested in object detection. Object detection problem is interesting because if we can detect objects of interest accurately, we can then count items, classify them, work out their spatial interaction or relationship and do much more. Unlike a classification task which aims to identify the most prominent or relevant object in an image, we are interested in knowing which, how many and where all objects are in an image or a video. Object detection is a much broader problem. Unlike a segmentation task which aims to assign each pixel in an image predefined classes, we are only interested in the whereabout or the vicinity of an object without concerning details at pixel level. Some computer vision tasks may not need to go down to the pixel level, including head counting, identifying the presence or absence of an objects, and so on.</p> <p>The need to detect an object or many objects in a scene is nothing new. However, the most exciting fact is that we can improve object detection performance by adapting convolutional neural network architecture which has proven to be suitable in image classification, natural language processing, computer vision, audio processing and more.</p> <h3 id="approaches">Approaches</h3> <p>My reading suggests that there are two main schools of thoughts. The first approach is a two-stage system, involving two separate models. The first model scans an image and then provides a basket of region candidates that likely contain an object of interests (region proposal stage). The second model can then do less work by taking in only these proposals and try to classify them. The famous member from this school is the R-CNN family.</p> <p>However, one of the main drawbacks of the two-stage system is its inefficiency in deployment as well as training. Two separate models are trained in series and both are needed during deployment, thereby making end-to-end training impossible. The second approach, by and large, tries to address this inefficiency. It advocates a single model that scans an image, estimates a pool of possible object locations and then classifies them. In this way, this model can be trained end-to-end, optimizing the complementary tasks simultaneously. For a long time, the two-stage approach yields better performance than a single-model approach. Until fairly recently, scientists have worked out a number of tricks that enables a single model to supersede two-stage models. Famous members include YOLO family, SSD, RetinaNet, etc.</p> <p><img src="/assets/images/toy/overview.png" alt="Picture description" />{width=10%}</p> <center> Network performance comparison on a public dataset (COCO). Source: <a href="https://arxiv.org/pdf/1911.09070.pdf"> EfficientDet: Scalable and Efficient Object Detection </a> </center> <p></p> <p>Furthermore, within this one-stage approach, we have seen two variants, namely anchor-based and anchor-free. The anchor-based approach relies on anchor boxes that are pre-determined and covered the entire image. Because they can be controlled via their aspect ratios and scales, these boxes capture object of various sizes and shapes. In much of the same way as region proposals, these anchor boxes serve the same purpose, but since they are set inside the model architecture, the model must go through and evaluate them all to detect any object of various shapes and sizes. This can be very useful if we have a rough idea on the kind of shapes and sizes of our objects of interest.</p> <p><img src="/assets/images/toy/anchorbox_predictionsrefine.png" alt="Picture description" width="1100px" /></p> <center> Anchor boxes and how they work. Source: <a href="https://www.mathworks.com/help/vision/ug/anchor-boxes-for-object-detection.html"> Anchor Boxes for Object Detection - MATLAB &amp; Simulink </a> </center> <p></p> <p>The anchor-free approach is closer conceptually to segmentation than anchor-based approach. Instead of relying on pre-defined anchor boxes as region candidates, anchor-free seeks to identify pixels that are useful for defining an object boundary. Since it operates on pixel level, it bears resemblance to segmentation tasks. For instance, to obtain object boundaries, cornerNet uses the corners while FCOS uses the center-of-mass.</p> <p><img src="/assets/images/toy/cornerNet.png" alt="Picture description" width="1100px" /></p> <center> The upper left and lower right corners are detected by cornerNet. Source: <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Hei_Law_CornerNet_Detecting_Objects_ECCV_2018_paper.pdf"> CornerNet: Detecting Objects as Paired Keypoints </a> </center> <p></p> <p><img src="/assets/images/toy/FCOS_centerness.png" alt="Picture description" width="1100px" /></p> <center> The center of mass of the child is detected. Source: <a href="https://arxiv.org/pdf/1904.01355.pdf"> FCOS: Fully Convolutional One-Stage Object Detection </a> </center> <p></p> <p>Modern object detection methods involve the following elements:</p> <ul> <li>Anchor boxes</li> <li>Feature pyramid network</li> <li>Focal loss</li> <li>Non-max suppression</li> </ul> <p>How these elements play out in the network architecture and during training will be delineated when we go through my python source code in the latter parts of this object detection series.</p> </div> <div id="disqus_thread"></div> </article> <article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-body" itemprop="articleBody"> <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> <div class="card-header"> <span class="title"> <i class="fa fa-share"></i> Share this to: </span> </div> <div id="share-bar"> <div class="share-buttons"> <a href="https://www.facebook.com/sharer/sharer.php?u=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook" > <i class="fa fa-facebook-official share-button"> facebook</i> </a> <a href="https://twitter.com/intent/tweet?text=Learning object detection part 1 - why object detection matters&url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter" > <i class="fa fa-twitter share-button"> twitter</i> </a> <a href="https://plus.google.com/share?url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Google+" > <i class="fa fa-google-plus share-button"> google</i> </a> <a href="https://www.pinterest.com/pin/create/button/?url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Pinterest" > <i class="fa fa-pinterest-p share-button"> pinterest</i> </a> <a href="https://www.tumblr.com/share/link?url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Tumblr" > <i class="fa fa-tumblr share-button"> tumblr</i> </a> <a href="http://www.reddit.com/submit?url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Reddit" > <i class="fa fa-reddit-alien share-button"> reddit</i> </a> <a href="https://www.linkedin.com/shareArticle?mini=true&url=/deep_learning/2020/07/31/Learning_Object_Detection_part1/&title=Learning object detection part 1 - why object detection matters&summary=&source=Wilson Fok" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn" > <i class="fa fa-linkedin share-button"> linkedin</i> </a> <a href="mailto:?subject=Learning object detection part 1 - why object detection matters&amp;body=Check out this site /deep_learning/2020/07/31/Learning_Object_Detection_part1/" title="Share via Email" > <i class="fa fa-envelope share-button"> email</i> </a> </div> </div> </div> </article> <script> var disqus_config = function () { this.page.url = "/deep_learning/2020/07/31/Learning_Object_Detection_part1/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/deep_learning/2020/07/31/Learning_Object_Detection_part1"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. Constructive feedback and insightful comments are very welcome!</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#Finance"></div> <li class="tag-head"> <a href="/blog/categories/Finance">Finance</a> </li> <a name="Finance"></a> <div id="#NLP"></div> <li class="tag-head"> <a href="/blog/categories/NLP">NLP</a> </li> <a name="NLP"></a> <div id="#Deep_Learning"></div> <li class="tag-head"> <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </li> <a name="Deep_Learning"></a> <div id="#Others"></div> <li class="tag-head"> <a href="/blog/categories/Others">Others</a> </li> <a name="Others"></a> <div id="#Reading"></div> <li class="tag-head"> <a href="/blog/categories/Reading">Reading</a> </li> <a name="Reading"></a> <div id="#Toastmasters"></div> <li class="tag-head"> <a href="/blog/categories/Toastmasters">Toastmasters</a> </li> <a name="Toastmasters"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> <li > <a href="/blog/categories">Categories</a> </li> <li > <a href="/gallery">Gallery</a> </li> <li > <a href="/contact">Contact Me</a> </li> </div> </div> </div> </div> </div> <footer> <p> Powered by Jekyll. Hosted on <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS <i class="fa fa-rss" aria-hidden="true"></i> </a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <!-- <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> --> <script src="/assets/js/mode-switcher.js"></script> <script src="/assets/js/slideshow.js"></script> </body> </html>
