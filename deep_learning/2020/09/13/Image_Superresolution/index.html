<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Wilson Fok - A data science enthusiast</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Image Super-resolution" /> <meta name="keywords" content="Image Super-resolution, Wilson Fok, Deep_Learning" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Wilson Fok" property="og:site_name"> <meta content="Image Super-resolution" property="og:title"> <meta content="article" property="og:type"> <meta content="A brief introduction to image super-resolution" property="og:description"> <meta content="/deep_learning/2020/09/13/Image_Superresolution/" property="og:url"> <meta content="2020-09-13T00:00:00+08:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="Deep_Learning" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="Image Super-resolution"> <meta content="Wilson Fok" property="og:site_name"> <meta name="twitter:url" content="/deep_learning/2020/09/13/Image_Superresolution/"> <meta name="twitter:description" content="Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. I also like to make new friends and connections. Let's connect! "> <!-- load layout style css --> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <!-- one or more of the below scripts does fancy word animation and dropdown menu --> <script src="/assets/extra_js/jquery-3.4.1.min.js"></script> <script src="/assets/extra_js/picturefill min/picturefill.min.js"></script> <script src="/assets/extra_js/instantsearch min/instantsearch.min.js"></script> <script src="/assets/extra_js/moment min/moment.min.js"></script> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> </head><body> <div class="container-fluid"><header> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Wilson Fok</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Wilson Fok</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog/categories">Categories</a> </li> <li class="nav-item"> <a class="nav-link" href="/contact">Contact Me</a> </li> </ul> </div> <ul class="nav justify-content-end"> <!-- <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> --> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/deep_learning/2020/09/13/Image_Superresolution/">Image Super-resolution</a></li> </ol> </nav> </div><div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <!-- <h1 class="post-title" itemprop="name headline">Image Super-resolution</h1> --> <h4 class="post-meta">A brief introduction to image super-resolution</h4> <p class="post-summary">Posted by : <img src="/assets/img/profile.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Wilson Fok</span> </span> on <time datetime="2020-09-13 00:00:00 +0800" itemprop="datePublished">Sep 13, 2020</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/deep_learning/2020/09/13/Image_Superresolution/"></span> <div class="post-categories"> Category : <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </div> </div> <div class="card-body" itemprop="articleBody"> <h3 id="background">Background</h3> <p>Convolutional neural networks have made many advances in the field of computer vision over the past decade. One such field is the study of super resolution. There are many applications that can benefit from increasing the resolution of an image to reveal more details. For example, high resolution medical MR scan takes longer to acquire but can reveal high level of anatomical details which can be useful for medical diagnosis. In this application, the motivation is to quickly obtain low resolution MR images but super-resolve them (which hopefully could be more efficient than scanning high resolution MR images) to obtain similar level of anatomical details as in high resolution MR images. Of course, the specific motivations behind super resolution differ across domains and applications. All in all, super-resolution is helpful when obtaining high resolution images is too costly or infeasible while image quality matters. This area of research is relatively new and exciting.</p> <h3 id="general-framework">General framework</h3> <p>In plain English, a super-resolution model is a mathematical function that takes low-resolution images and produces its high-resolution version. Because low-resolution images contain less or incomplete information to fully reconstruct them, this problem is, in theory, ill-posed.</p> <p>To train a super-resolution model, we collect a dataset of high-resolution images, degrade them to mimic low-resolution images in real-world, and train a model to super resolve these image pairs. The degradation begins by applying Gaussian smoothing/ Gaussian filtering with sigma being a function of a scale factor on the high-resolution images and then down-samples (bicubic down-sampling) them to a scale factor, a value typically between 2x and 4x.</p> <p>The model regards the high-resolution input images as ground truth and learns to scale the low-resolution (LR) images up to match its high-resolution images. The concept of supervised learning is portrayed in the figure below.</p> <p><img src="/assets/images/image_superresolution/general_Framework.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <p>A variant of this concept comes from this paper, <a href="https://arxiv.org/pdf/2008.11921">Unsupervised MRI Super-Resolution using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors.</a></p> <p>In addition to these image pairs, the model receives high-resolution images of the same structure but from a different modality.</p> <p><img src="/assets/images/image_superresolution/MRI_framework.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://arxiv.org/pdf/2008.11921"> Unsupervised MRI Super-Resolution using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors </a> </center> <p></p> <p>In figure (a) above, the model estimates medium-resolution images (H, W) from low-resolution images (H/s, W/s). Before handing over to the network, the low-resolution images are upsampled to (H, W) so that its resolution is on par with the final estimate that will be made by the network. The loss is calculated based on the difference of the estimates to the ground truth. During inference, the model estimates the super-resolved images (sH, sW) from up-sampled raw images (sH, sW).</p> <p>In the figure (b) above, once again, the model takes in (H, W) images (from top to middle on the left-hand side) as well as the images of another modality (H, W) (from bottom to middle on the left-hand side). The intention is to use the information from multiple modalities to super resolve. One very critical factor is to have images from different modalities well aligned. During inference, the model fuses images from multiple modalities to super-resolve low resolution images from the desired modality.</p> <h3 id="another-way-of-looking-at-the-general-framework">Another way of looking at the general framework</h3> <p>A major drawback of the aforementioned framework is the degradation / down-sampling process may not necessarily reflect underlying processes that have brought about low-resolution images. By making an assumption that the degradation could be described by a fairly simple and straightforward blurring and down-sampling steps, we fail to teach a model to learn the more realistic/ real-world degradation processes. Thus, super-resolution models often perform poorly on images that are degraded by anything but straightforward smoothing and subsampling.</p> <p>To tackle this issue, zero short super-resolution model has been proposed in this paper, <a href="https://arxiv.org/pdf/1712.06087.pdf">Zero-Shot” Super-Resolution using Deep Internal Learning</a></p> <p><img src="/assets/images/image_superresolution/zssr_castle.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://arxiv.org/pdf/1712.06087.pdf"> Zero-Shot” Super-Resolution using Deep Internal Learning </a> </center> <p></p> <p>Zero shot super resolution is very interesting. In figure 3, the authors use this example to illustrate the point that features in an image may not exist elsewhere and therefore are “unlearnable” for the network that are trained on millions of other unrelated images.</p> <p>That idea leads us to say that the goal of the network is to learn high-resolution features from one part of the image and apply these features to super-resolve the low-resolution patches at a different image location. This idea has been used heavily in non-local means denoising techniques. Below is an example of such techniques.</p> <p><img src="/assets/images/image_superresolution/non_localmeans.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://scikit-image.org/docs/dev/auto_examples/filters/plot_nonlocal_means.html"> Non-local means denoising for preserving textures </a> </center> <p></p> <h3 id="how-should-we-apply-this-idea-in-the-field-of-super-resolution">How should we apply this idea in the field of super resolution?</h3> <p><img src="/assets/images/image_superresolution/zssr_framework.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://arxiv.org/pdf/1712.06087.pdf"> Zero-Shot” Super-Resolution using Deep Internal Learning </a> </center> <p></p> <p>Figure 4a shows the typical paradigm found in many papers. High-resolution images are degraded by a simple down-sampling operation; a network is trained to undo this down-sampling and to increase the resolution, figuratively shown by the size of the image stacks. At test time, the model applies the same undoing operation to unknown images. Figure 4b shows the zero-shot paradigm in which training and testing use the same set of images. High resolution (HR) – low resolution (LR) pairs are created by recursively downscaling the higher resolution one to create more lower resolution samples by a fixed scaling factor, s.</p> <p><img src="/assets/images/image_superresolution/eye_testboard.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://arxiv.org/pdf/1712.06087.pdf"> Zero-Shot” Super-Resolution using Deep Internal Learning </a> </center> <p></p> <p>What zero-shot model learns? To demonstrate what the zero-shot model has learned, Figure 5 shows an interesting property of zero shot super resolution method. When there is a high degree of self-similarity in the image, zero shot super resolution method works very well, better than the other two methods on the left. It turns out that this self-similarity is useful for “real-world” images. Figure 7 shows 3 examples that are degraded by JPEG compression, noisy and non-ideal downscaling. Although zero shot super resolution solutions are far from perfect, I think they are fairly intuitive in a sense that I would mentally draw these images in a similar fashion.</p> <p><img src="/assets/images/image_superresolution/non_ideal.png" alt="Picture description" width="1400px" /></p> <center> From <a href="https://arxiv.org/pdf/1712.06087.pdf"> Zero-Shot” Super-Resolution using Deep Internal Learning </a> </center> <p></p> <p>For further information, I encourage readers to find more examples from <a href="http://www.wisdom.weizmann.ac.il/~vision/zssr/">the authors’ homepage</a></p> <h3 id="generative-adversarial-neural-network-as-a-universal-degradation-function">Generative adversarial neural network as a universal degradation function</h3> <p>Another idea is to let a generative adversarial neural network (GAN) to approximate the unknown degradation function and therefore to undo the degradation on the images to obtain its high-resolution version. <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf">Unpaired Image Super-Resolution using Pseudo-Supervision</a></p> <p><img src="/assets/images/image_superresolution/gan_framework.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <p>According to the authors of this paper, Unpaired Image Super-Resolution using Pseudo-Supervision, there are two main approaches on how to go about training such GANs (shown in figure 2). The direct approach is to train a generator to super-resolve images as well as to train a discriminator to distinguish whether the images are “genuine” or fake. This paradigm relies on the discriminator classification loss to optimize the generator and precludes the use of a more direct loss, a pixelwise loss between the generated images and the high-resolution ground-truth images on the generator. This loss is a major drawback in this paradigm of network training.</p> <p>The indirect approach uses the generator to create degraded low-resolution images. The discriminator distinguishes the differences between the “ideal” low resolution images (ground-truth real images) and generated low resolution images. While this approach uses an up-sampling model to super resolve the low-resolution images and therefore it permits the use of pixel-wise losses, it runs into big problems as, most of the time, the “ideal” differs from “real-world” situations.</p> <h3 id="how-could-we-use-generative-adversarial-neural-networks-for-super-resolution">How could we use generative adversarial neural networks for super resolution?</h3> <p>Before diving into this proposal, let’s take a step back to review the basic of a cycle GAN in the diagram below.</p> <p><img src="/assets/images/image_superresolution/cycle_gan.png" alt="Picture description" width="1400px" /></p> <center>The tenets of cycle GAN can be summarized in the above diagram. In essence, image X can be transformed by a GAN (G) to image Y which can also be restored back to image X by a GAN (F). This seems intuitive for cases we expect reversibility. Usually, the restored image X does not appear to be exactly like X, so the discrepancy is measured by cycle-consistency loss. The discriminator Dx and Dy are there to ensure X and Y appear realistic. </center> <p></p> <p>Figure 3 shows the entire framework. Please note the color of the arrow as it is extremely important to differentiate the training and testing phrases. Let’s start with the training phrase. The very first impression is that all models inside the framework are end-to-end trainable.</p> <p><img src="/assets/images/image_superresolution/gan_whole_framework.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <h4 id="adversarial-losses">Adversarial losses</h4> <p>There are 3 discriminators Dx, Dy down and Dx up. Dx distinguishes whether the low-resolution noisy images look real and noisy. It tries to help (Gy down x) to generate realistic real-world low-resolution images. Dy down distinguishes whether clean low-resolution clean images look real and clean. The meaning of clean is that the effect of non-ideal degradation such as noise has been removed. It tries to help (Gxy down) to generate high-quality low-resolution images. Dx up distinguishes whether the high-resolution images look real and clean. It tries to help (Uy down y) to super resolve realistic features to the level of pixels.</p> <h5 id="cycle-consistency-loss">Cycle consistency loss</h5> <p>Unlike the full cycle consistency loss, here the loss is calculated only from clean LR to noisy LR (Gy down x) back to clean LR or pseudo clean LR (Gxy down). The rationale is that while many different noisy images can be filtered to obtain the same clean image, it is not very required to learn to map the same clean images to their many different noisy versions.</p> <p>Here are some examples of fake degraded images from a clean image:</p> <p><img src="/assets/images/image_superresolution/noisy_clean.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <p>To obtain the high-resolution images from low-resolution images, an up-sampler (Uy down y) is trained with pixelwise L1 loss.</p> <p>Thus, the critical step to undo the degradation occurs only at low-resolution steps. Up-sampling is done by another model, making the division of labor quite obvious. This setup is very interesting as other papers try to do super resolution simultaneously with up-sampling.</p> <p>The training (green arrow) starts from high resolution castle image. It is downscaled to create the clean low-resolution castle image. (Dy down) learns what a clean low image should look like. (Gy down x) creates a noisy version of the clean from clean. The Dx learns what a real-world noisy image should look like from a low-resolution image (cat face). Dx feedbacks how realistic the noisy images are for (Gy down x). The (Gxy down) cleans up the noisy image to produce the pseudo clean LR. (Dy down) learns the difference between the pseudo-clean and clean. This helps the (Gxy down) to be “cycle consistent” by making pseudo clean images look clean. (Uy down y) learns to super resolve the pseudo-clean LR and receives feedback via pixelwise loss. (Dx up) does not provide losses to (Uy down y). Instead, its loss goes to the other two generators.</p> <p>The testing (black arrow) starts from a low noisy real-world image (cat face). (Gxy down) cleans the image to create a pseudo-clean version. This version is then super resolved by (Uy down y).</p> <p>Let’s take a look at the results</p> <p><img src="/assets/images/image_superresolution/squirrels.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <p><img src="/assets/images/image_superresolution/birds.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <p>This comparison of the various methods is very interesting. Note that ZZSR cannot filter out the noisy sky but the author’s proposal (ours) can.</p> <p><img src="/assets/images/image_superresolution/roads.png" alt="Picture description" width="1400px" /></p> <center> From <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf"> Unpaired Image Super-Resolution using Pseudo-Supervision </a> </center> <p></p> <h3 id="my-final-thoughts">My final thoughts:</h3> <p>I personally would like to see some less successful examples to get a more comprehensive understanding of the methods. However, this is a very rare practice as I have seen only very few papers have uploaded failure cases in a demonstration.</p> <h3 id="what-is-next">What is next?</h3> <p>Super resolution on videos?</p> <h3 id="references">References</h3> <ul> <li><a href="https://arxiv.org/pdf/2008.11921">Unsupervised MRI Super-Resolution using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors.</a></li> <li><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf">Unpaired Image Super-Resolution using Pseudo-Supervision</a></li> <li><a href="https://arxiv.org/pdf/1712.06087.pdf">Zero-Shot” Super-Resolution using Deep Internal Learning</a></li> </ul> </div> <div id="disqus_thread"></div> </article> <script> var disqus_config = function () { this.page.url = "/deep_learning/2020/09/13/Image_Superresolution/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/deep_learning/2020/09/13/Image_Superresolution"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. Constructive feedback and insightful comments are very welcome!</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#Finance"></div> <li class="tag-head"> <a href="/blog/categories/Finance">Finance</a> </li> <a name="Finance"></a> <div id="#NLP"></div> <li class="tag-head"> <a href="/blog/categories/NLP">NLP</a> </li> <a name="NLP"></a> <div id="#Deep_Learning"></div> <li class="tag-head"> <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </li> <a name="Deep_Learning"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> <li > <a href="/blog/categories">Categories</a> </li> <li > <a href="/contact">Contact Me</a> </li> </div> </div> </div> </div> </div> <footer> <p> Powered by Jekyll. Hosted on <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS <i class="fa fa-rss" aria-hidden="true"></i> </a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <!-- <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> --> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
