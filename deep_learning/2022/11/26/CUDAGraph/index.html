<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Wilson Fok - A data science enthusiast</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="CUDA Graphs in Pytorch" /> <meta name="keywords" content="CUDA Graphs in Pytorch, Wilson Fok, Deep_Learning" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Wilson Fok" property="og:site_name"> <meta content="CUDA Graphs in Pytorch" property="og:title"> <meta content="article" property="og:type"> <meta content="Extending Pytorch CUDA Graph tutorial" property="og:description"> <meta content="/deep_learning/2022/11/26/CUDAGraph/" property="og:url"> <meta content="2022-11-26T00:00:00+08:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="/assets/img/posts//assets/img/deepLearning.jpg" property="og:image"> <meta content="Deep_Learning" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="CUDA Graphs in Pytorch"> <meta content="Wilson Fok" property="og:site_name"> <meta name="twitter:url" content="/deep_learning/2022/11/26/CUDAGraph/"> <meta name="twitter:description" content="Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. I also like to make new friends and connections. Let's connect! "> <!-- load layout style css --> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <!-- one or more of the below scripts does fancy word animation and dropdown menu --> <script src="/assets/extra_js/jquery-3.4.1.min.js"></script> <script src="/assets/extra_js/picturefill min/picturefill.min.js"></script> <script src="/assets/extra_js/instantsearch min/instantsearch.min.js"></script> <script src="/assets/extra_js/moment min/moment.min.js"></script> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> </head><body> <div class="container-fluid"><header> <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script> <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css"> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Wilson Fok</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Wilson Fok</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog/categories">Categories</a> </li> <li class="nav-item"> <a class="nav-link" href="/gallery">Gallery</a> </li> <li class="nav-item"> <a class="nav-link" href="/contact">Contact Me</a> </li> </ul> </div> <ul class="nav justify-content-end"> <!-- <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> --> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/deep_learning/2022/11/26/CUDAGraph/">CUDA Graphs in Pytorch</a></li> </ol> </nav> </div><div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <h1 class="post-title" itemprop="name headline">CUDA Graphs in Pytorch</h1> <p></p> <h6 class="post-meta"> <i> Summary : Extending Pytorch CUDA Graph tutorial</i> </h6> <p class="post-summary">Posted by : <img src="/assets/img/profile.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Wilson Fok</span> </span> on <time datetime="2022-11-26 00:00:00 +0800" itemprop="datePublished">Nov 26, 2022</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/deep_learning/2022/11/26/CUDAGraph/"></span> <div class="post-categories"> Category : <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </div> </div> <div class="card-body" itemprop="articleBody"> <h2 id="introduction">Introduction</h2> <p>Since its debut in CUDA 10, we have been waiting for Pytorch to add CUDA Graphs features. It is great to see that, by the end of 2021, Pytorch has incorporated CUDA Graphs along with tutorials and documentation on how it works and how to use it.</p> <p>For the sake of brevity, I shall not repeat what is officially available on Pytorch tutorials, but instead I shall focus on some useful tricks for learning about CUDA Graphs. I strongly encourage readers to check out the blog on CUDA Graphs at <a href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/">https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/</a>. I find the article very helpful and informative. However, I want to extend the tutorial a bit further. Hence, I am writing this post.</p> <h2 id="prerequisite">Prerequisite</h2> <ul> <li>Pytorch 1.12.1</li> <li>NVIDIA GeForce GTX 1650 Ti</li> <li>CUDA 11.3</li> <li>Windows 10</li> </ul> <h2 id="problems">Problems</h2> <p>When I try to understand the API example in the tutorial, I run into this situation when I print the torch.cudaStream object and the torch.cuda.CUDAGraph object.</p> <blockquote> <p>&lt;torch.cuda.Stream device=cuda:0 cuda_stream=0x20af329de50&gt;</p> </blockquote> <blockquote> <p>&lt;torch.cuda.graphs.CUDAGraph object at 0x0000018E91AD4540&gt;</p> </blockquote> <p>All I can see is that I have created both objects and they are sitting at a specific location/address on memory. Yet, it tells me nothing about any change I make to the graphs and streams as I experiment them.</p> <p>A dummy operation and tensor are therefore added to reveal the subtle difference and the functioning of this API tutorial.</p> <p>Below is the original tutorial.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Placeholders used for capture
</span><span class="n">static_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="c1"># warmup
# Uses static_input and static_target here for convenience,
# but in a real setting, because the warmup includes optimizer.step()
# you must use a few batches of real data.
</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">Stream</span><span class="p">()</span>
<span class="n">s</span><span class="p">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">())</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">stream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">().</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="c1"># capture
</span><span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">CUDAGraph</span><span class="p">()</span>
<span class="c1"># Sets grads to None before capture, so backward() will create
# .grad attributes with allocations from the graph's private pool
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="n">static_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
    <span class="n">static_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">static_y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
    <span class="n">static_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">real_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_target</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">,</span> <span class="n">real_targets</span><span class="p">):</span>
    <span class="c1"># Fills the graph's input memory with new data to compute on
</span>    <span class="n">static_input</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">static_target</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># replay() includes forward, backward, and step.
</span>    <span class="c1"># You don't even need to call optimizer.zero_grad() between iterations
</span>    <span class="c1"># because the captured backward refills static .grad tensors in place.
</span>    <span class="n">g</span><span class="p">.</span><span class="n">replay</span><span class="p">()</span>
    <span class="c1"># Params have been updated. static_y_pred, static_loss, and .grad
</span>    <span class="c1"># attributes hold values from computing on this iteration's data.
</span>
</code></pre></div></div> <p>If this code looks unfamiliar, please visit <a href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/">https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/</a>. The tutorial suggests that we should start the process of building our own CUDA Graph by doing a “warm up” first. In a “warm up”, we stream capture a linear sequence of execution that occurs on a specific device (in this case, cuda:0). Even though the tutorial uses random data, we ought to use a few batches of real data. Then, we repeat the exact sequence in graph capture. Finally, we replay the captured graph to train a model on real data.</p> <h2 id="lesson-1-we-perform-computation-during-warm-up-but-not-graph-capture">Lesson 1: we perform computation during warm up but not graph capture.</h2> <p>Here is my version of the same tutorial on Lesson 1.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Placeholders used for capture
</span><span class="n">static_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'Initial: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

<span class="c1"># warmup
# Uses static_input and static_target here for convenience,
# but in a real setting, because the warmup includes optimizer.step()
# you must use a few batches of real data.
</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">Stream</span><span class="p">()</span>
<span class="n">s</span><span class="p">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">())</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">stream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>

    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>

<span class="s">'''
A CUDA stream is a linear sequence of execution that belongs to a specific device, independent from other streams
'''</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">().</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'After stream capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
<span class="c1"># capture
</span><span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">CUDAGraph</span><span class="p">()</span>
<span class="c1"># Sets grads to None before capture, so backward() will create
# .grad attributes with allocations from the graph's private pool
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>

    <span class="n">static_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
    <span class="n">static_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">static_y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
    <span class="n">static_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'After Graph Capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

<span class="n">ZERO</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ZERO</span><span class="p">)</span>

<span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">real_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_target</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">,</span> <span class="n">real_targets</span><span class="p">):</span>
    <span class="c1"># Fills the graph's input memory with new data to compute on
</span>    <span class="n">static_input</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">static_target</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># replay() includes forward, backward, and step.
</span>    <span class="c1"># You don't even need to call optimizer.zero_grad() between iterations
</span>    <span class="c1"># because the captured backward refills static .grad tensors in place.
</span>    <span class="n">g</span><span class="p">.</span><span class="n">replay</span><span class="p">()</span>
    <span class="c1"># Params have been updated. static_y_pred, static_loss, and .grad
</span>    <span class="c1"># attributes hold values fr
</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'After replay: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
</code></pre></div></div> <p>Static_counter has been added as a dummy tensor, so that we can keep track of the impact during streaming, graph capture and graph replay.</p> <p>Console outputs are as follows:</p> <blockquote> <p>Initial: static_counter tensor([0.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After stream capture: static_counter tensor([1.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After Graph Capture: static_counter tensor([1.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After replay: static_counter tensor([10.], device=’cuda:0’)</p> </blockquote> <p>We observe that static counter’s value has increased by +1 during stream capture, but not graph capture. Therefore, we conclude that we perform no computation during graph capture! Just prior to replay, we reset static counter to zero. After replay, static counter value has raised to 10, reflecting the number of iterations of the for loop.</p> <h2 id="lesson-2-only-what-happens-during-graph-capture-matters">Lesson 2: only what happens during graph capture matters.</h2> <p>Stream capture aims only at debugging and sanity check. Lesson 2 script is as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Placeholders used for capture
</span><span class="n">static_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'Initial: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

<span class="c1"># warmup
# Uses static_input and static_target here for convenience,
# but in a real setting, because the warmup includes optimizer.step()
# you must use a few batches of real data.
</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">Stream</span><span class="p">()</span>
<span class="n">s</span><span class="p">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">())</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">stream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>

    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="s">'''
A CUDA stream is a linear sequence of execution that belongs to a specific device, independent from other streams
'''</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">().</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'After stream capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
<span class="c1"># capture
</span><span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">CUDAGraph</span><span class="p">()</span>
<span class="c1"># Sets grads to None before capture, so backward() will create
# .grad attributes with allocations from the graph's private pool
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>

    <span class="n">static_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
    <span class="n">static_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">static_y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
    <span class="n">static_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'After Graph Capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

<span class="n">ZERO</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ZERO</span><span class="p">)</span>

<span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">real_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_target</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">,</span> <span class="n">real_targets</span><span class="p">):</span>
    <span class="c1"># Fills the graph's input memory with new data to compute on
</span>    <span class="n">static_input</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">static_target</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># replay() includes forward, backward, and step.
</span>    <span class="c1"># You don't even need to call optimizer.zero_grad() between iterations
</span>    <span class="c1"># because the captured backward refills static .grad tensors in place.
</span>    <span class="n">g</span><span class="p">.</span><span class="n">replay</span><span class="p">()</span>
    <span class="c1"># Params have been updated. static_y_pred, static_loss, and .grad
</span>    <span class="c1"># attributes hold values fr
</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'After replay: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

</code></pre></div></div> <p>I deliberately remove the increments of static counter during stream capture but keep it during graph capture. Console outputs are as follows:</p> <blockquote> <p>Initial: static_counter tensor([0.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After stream capture: static_counter tensor([0.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After Graph Capture: static_counter tensor([0.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After replay: static_counter tensor([10.], device=’cuda:0’)</p> </blockquote> <p>Since its removal, static counter value remains at zero after stream capture. However, after replay, our graph actually performs 10 iterations of addition!</p> <p>Of course, in practice, we should execute the same sequence during stream capture and graph capture because we can catch bugs only during stream capture when computation is verified and performed on the device.</p> <h2 id="lesson-3-we-can-explicitly-capture-a-for-loop-in-a-graph">Lesson 3: we can explicitly capture a for loop in a graph.</h2> <p>The script below shows that we add a for loop during both stream capture and graph capture.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Placeholders used for capture
</span><span class="n">static_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'Initial: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
<span class="c1"># warmup
# Uses static_input and static_target here for convenience,
# but in a real setting, because the warmup includes optimizer.step()
# you must use a few batches of real data.
</span><span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">Stream</span><span class="p">()</span>
<span class="n">s</span><span class="p">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">())</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">stream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">().</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'After stream capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
<span class="c1"># capture
</span><span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">CUDAGraph</span><span class="p">()</span>
<span class="c1"># Sets grads to None before capture, so backward() will create
# .grad attributes with allocations from the graph's private pool
</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">static_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
        <span class="n">static_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">static_y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
        <span class="n">static_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

<span class="k">print</span> <span class="p">(</span><span class="s">'After Graph Capture: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>

<span class="n">ZERO</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
<span class="n">static_counter</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ZERO</span><span class="p">)</span>  

<span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">real_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_target</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">,</span> <span class="n">real_targets</span><span class="p">):</span>
    <span class="c1"># Fills the graph's input memory with new data to compute on
</span>    <span class="n">static_input</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">static_target</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># replay() includes forward, backward, and step.
</span>    <span class="c1"># You don't even need to call optimizer.zero_grad() between iterations
</span>    <span class="c1"># because the captured backward refills static .grad tensors in place.
</span>    <span class="n">g</span><span class="p">.</span><span class="n">replay</span><span class="p">()</span>
    <span class="c1"># Params have been updated. static_y_pred, static_loss, and .grad
</span>    <span class="c1"># attributes hold values from computing on this iteration's data.
</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'After replay: static_counter '</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">)</span>
</code></pre></div></div> <p>Console outputs are as follows:</p> <blockquote> <p>Initial: static_counter tensor([0.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After stream capture: static_counter tensor([3.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After Graph Capture: static_counter tensor([3.], device=’cuda:0’)</p> </blockquote> <blockquote> <p>After replay: static_counter tensor([30.], device=’cuda:0’)</p> </blockquote> <p>Interestingly, static counter value has risen by the multiplication of the number of iterations of the two for loops. Thus, a “single” replay is in fact a series of 3 repeated executions.</p> <h2 id="speed">Speed</h2> <p>In this toy example, CUDA Graph offers a 4% reduction in training time on average. Nonetheless, this speed up is not as impressive as the one realized by the official examples/ case studies.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span><span class="p">,</span> <span class="n">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">setup</span><span class="p">():</span>

    <span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># Placeholders used for capture
</span>    <span class="n">static_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">static_target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">static_counter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

    <span class="c1"># warmup
</span>    <span class="c1"># Uses static_input and static_target here for convenience,
</span>    <span class="c1"># but in a real setting, because the warmup includes optimizer.step()
</span>    <span class="c1"># you must use a few batches of real data.
</span>    <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">Stream</span><span class="p">()</span>
    <span class="n">s</span><span class="p">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">())</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">stream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">current_stream</span><span class="p">().</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="c1"># capture
</span>    <span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">CUDAGraph</span><span class="p">()</span>
    <span class="c1"># Sets grads to None before capture, so backward() will create
</span>    <span class="c1"># .grad attributes with allocations from the graph's private pool
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
        <span class="n">static_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span>
        <span class="n">static_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">static_y_pred</span><span class="p">,</span> <span class="n">static_target</span><span class="p">)</span>
        <span class="n">static_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

    <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">static_input</span><span class="p">,</span> <span class="n">static_target</span><span class="p">,</span> <span class="n">static_counter</span>

<span class="k">def</span> <span class="nf">test_with_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">static_input</span><span class="p">,</span> <span class="n">static_target</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>

    <span class="n">real_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_input</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>
    <span class="n">real_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">static_target</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>

    <span class="n">ZERO</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">static_counter</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">ZERO</span><span class="p">)</span> 

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">real_inputs</span><span class="p">,</span> <span class="n">real_targets</span><span class="p">):</span>
        <span class="c1"># Fills the graph's input memory with new data to compute on
</span>        <span class="n">static_input</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">static_target</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="c1"># replay() includes forward, backward, and step.
</span>        <span class="c1"># You don't even need to call optimizer.zero_grad() between iterations
</span>        <span class="c1"># because the captured backward refills static .grad tensors in place.
</span>        <span class="n">g</span><span class="p">.</span><span class="n">replay</span><span class="p">()</span>
        <span class="c1"># Params have been updated. static_y_pred, static_loss, and .grad
</span>        <span class="c1"># attributes hold values from computing on this iteration's data.
</span>    <span class="c1"># print ('After training: static_counter ', static_counter)
</span>    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>    
    <span class="c1"># print ('After training: static_counter ', static_counter)
</span>    <span class="k">return</span> <span class="n">time_elapsed</span> <span class="o">/</span> <span class="n">M</span>


<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>

    <span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">),</span>
                                <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)).</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># Placeholders used for capture
</span>    <span class="n">static_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>
    <span class="n">static_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D_out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>
    <span class="n">static_counter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span><span class="p">)</span>

    <span class="c1"># print ('Initial: static_counter ', static_counter)
</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">static_input</span><span class="p">,</span> <span class="n">static_target</span><span class="p">):</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">static_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span>  <span class="mf">1.0</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>    
    <span class="c1"># print ('After training: static_counter ', static_counter)
</span>    <span class="k">return</span> <span class="n">time_elapsed</span> <span class="o">/</span> <span class="n">M</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    
    <span class="k">print</span> <span class="p">(</span><span class="n">t0</span> <span class="p">:</span><span class="o">=</span> <span class="n">test</span><span class="p">())</span>

    <span class="n">g</span><span class="p">,</span> <span class="n">static_input</span><span class="p">,</span> <span class="n">static_target</span><span class="p">,</span> <span class="n">static_counter</span> <span class="o">=</span> <span class="n">setup</span><span class="p">()</span>
    <span class="k">print</span> <span class="p">(</span><span class="n">t1</span><span class="p">:</span><span class="o">=</span> <span class="n">test_with_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">static_input</span><span class="p">,</span> <span class="n">static_target</span><span class="p">,</span> <span class="n">static_counter</span><span class="p">))</span>

    <span class="k">print</span> <span class="p">((</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span><span class="o">/</span> <span class="n">t0</span><span class="p">)</span>
</code></pre></div></div> <p>It is worth noting that whenever performance we measure, it is very crucial to separate the CPU launch time and the GPU computation time. As explained in the official tutorial, CPU launch time can be slow. Instead of timing test() and test_with_graph(), I therefore choose to time the for loop.</p> <h2 id="conclusion">Conclusion</h2> <p>CUDA Graph is quite useful for speeding training up. Especially, CUDA Graph is so convenient to implement and deploy. As CUDA and Pytorch improve symbiotically, we have more tricks to train better AI models.</p> </div> <div id="disqus_thread"></div> </article> <script> var disqus_config = function () { this.page.url = "/deep_learning/2022/11/26/CUDAGraph/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/deep_learning/2022/11/26/CUDAGraph"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. Constructive feedback and insightful comments are very welcome!</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#Finance"></div> <li class="tag-head"> <a href="/blog/categories/Finance">Finance</a> </li> <a name="Finance"></a> <div id="#NLP"></div> <li class="tag-head"> <a href="/blog/categories/NLP">NLP</a> </li> <a name="NLP"></a> <div id="#Deep_Learning"></div> <li class="tag-head"> <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </li> <a name="Deep_Learning"></a> <div id="#Others"></div> <li class="tag-head"> <a href="/blog/categories/Others">Others</a> </li> <a name="Others"></a> <div id="#Reading"></div> <li class="tag-head"> <a href="/blog/categories/Reading">Reading</a> </li> <a name="Reading"></a> <div id="#Toastmaster"></div> <li class="tag-head"> <a href="/blog/categories/Toastmaster">Toastmaster</a> </li> <a name="Toastmaster"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> <li > <a href="/blog/categories">Categories</a> </li> <li > <a href="/gallery">Gallery</a> </li> <li > <a href="/contact">Contact Me</a> </li> </div> </div> </div> </div> </div> <footer> <p> Powered by Jekyll. Hosted on <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS <i class="fa fa-rss" aria-hidden="true"></i> </a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <!-- <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> --> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
