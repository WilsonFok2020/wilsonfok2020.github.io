<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Gaussian Splatting - Gaussian Splatting | Wilson Fok</title> <meta name="generator" content="Jekyll v3.9.3" /> <meta property="og:title" content="Gaussian Splatting - Gaussian Splatting" /> <meta name="author" content="Wilson Fok" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="How to perform Gaussian Splatting? The Gaussian Splatting Python scripts are provided in the original publication - 3D Gaussian Splatting for Real-Time Radiance Field Rendering. To use these scripts, you must first set up the required Python environment. While the setup may seem straightforward, I encountered several challenges during the process that I document here to help others avoid them. The code was first published in 2023, and many dependencies are no longer readily available or compatible with the latest software versions. A common mistake I made was attempting to run it with the most up-to-date packages, which led to numerous incompatibility issues. Hardware Specification GPU: Nvidia GeForce RTX 4070, 8 GB VRAM Driver version: 580.88 CUDA: 11.8 CPU: Intel i7-13620H OS: Windows 11 RAM: 40 GB (Windows page file 60 GB) Python and Package installation I installed both Python 3.8 and 3.10, finding Python 3.10 generally more compatible with most packages since 3.8 is becoming obsolete. Most packages install smoothly as pre-compiled wheels, but some, especially CUDA-related custom modules in Gaussian Splatting, require local compilation. Making sure the compilation tools are of the compatible version with these packages can be tricky. Since most of the time, the authors would not have tested many cases and their success configuration may not be the same as what I have got. After many experiments by trial and error, I have worked out a solution as follows: Microsoft Visual Studio Build Tools 2019 (v143 toolset): Avoid the latest Visual Studio versions like 17.14, which are not backward compatible. Always compile from the VS x64 Native Tools Command Prompt to ensure the correct compiler is called. With this setup, I could follow the official installation guides without issues. Tips and Common Issues Tips: If we use install torch and torch related packages on pip, it is likely that pip install the CPU-only version. So please visit Pytorch official website to get the CUDA-enabled version that is compatible for your device. Watch out for: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized. OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/. Crash and blue-screen Initially, frequent crashes were blamed on Python or the packages. In hindsight, I have figured out the importance and usefulness of windows operating system event report feature. On many occasions, the system crashed due to mis-configured libraries and system settings. Of course, I had no idea at the beginning and mis-attributed the crash due to Python and its packages. After reinstalling Python and its packages, the situation showed no sign of any improvement. I then studied the event report features on windows to get a better understanding on what did occur right before a crash (Windows Event Viewer). The WINDGB tool was very useful because a dump file was generated to record the exact event and all the related programs or dll at that time right after the crash. WINDGB revealed the core issue - multiple CUDA versions installed on the system. I had installed and uninstalled different CUDA versions which corrupted Nvidia dll and caused several errors. Final solution: Thus, the final solution is to update all the graphical drivers and libraries because all evidence pointed to an urgent driver updates (Nvidia and Intel graphic cards). After a CLEAN installation of the latest drivers, the crash had ceased eventually . As for CUDA, keep one and only one version (in this case CUDA 11.8) on the system. Otherwise, python setup may compile the source code against the wrong version. In addition to software upgrades, shutdown all memory intensive programs prior to running Python and increase Windows’ page memory as much as possible. After this step, system stability was restored and crashes stopped. Training 3D Gaussian Splatting # Run 3D AND 2D gaussian splatting train script python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 &amp;&amp; python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20\15 -m ./outputs/VID_20250725_173235_20_93\15 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 Note: this laptop has limited GPU memory. See computer specification, so the images are downscaled by a multiple of 8. i.e. from 1080x1920 -&gt; 135x240 Results The Gaussian Splatting model was evaluated on a C-arm machine configured in both Anterior-Posterior (AP) and Medial-Lateral (ML) poses. There are two ways to assess the quality: Quantitative metrics: SSIM, PSNR, and LPIPS scores provide numerical evaluation of image quality. Qualitative visualization: Using Splatviz, which allows intuitive inspection of the reconstructions. SSIM, PSNR, LPIPS # evaluation script (evaluation on test images , a total of 53) python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_172445_20_93 python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_175410_20_93 python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_173235_20_93 Anterior Posterior AP Orientation At iteration 7000 SSIM : 0.9049926 PSNR : 25.9037876 LPIPS: 0.1312765 At iteration 30000 SSIM : 0.9583084 PSNR : 30.5848618 LPIPS: 0.0602733 At iteration 93000 SSIM : 0.9692391 PSNR : 32.1568565 LPIPS: 0.0452350 Medial Lateral Vertical camera frames At iteration 7000 SSIM : 0.9277247 PSNR : 26.7998466 LPIPS: 0.0987048 At iteration 30000 SSIM : 0.9654269 PSNR : 30.7180729 LPIPS: 0.0463373 At iteration 93000 SSIM : 0.9736962 PSNR : 32.5040054 LPIPS: 0.0358106 Horizontal camera frames At iteration 7000 SSIM : 0.8346600 PSNR : 22.8985519 LPIPS: 0.2103405 At iteration 30000 SSIM : 0.9369362 PSNR : 28.4063663 LPIPS: 0.0972803 At iteration 93000 SSIM : 0.9571357 PSNR : 30.3842888 LPIPS: 0.0668879 All in all, the Gaussian Splatting results are very good. Indeed, the more iterations, the better the quality. (albeit the improvement slows drastically) The videos were shot in two different camera orientations. The vertical and the horizontal show very similar end results. I think so long as the video quality is good and the reconstruction is accurate, Gaussian Splatting is quite robust that camera orientation does not matter. Splatviz # Run splat-vis for visualization python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93_previous\point_cloud\iteration_93000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93\point_cloud\iteration_30000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93\point_cloud\iteration_93000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_175410_20_93\point_cloud\iteration_93000 Anterior Posterior Medial Lateral Zoom in block to indicate filtering script for Gaussian ellipsoids display filter Gaussian ellipsoids mask = torch.linalg.norm(gs._scaling, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] mask = torch.linalg.norm(gs._opacity, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] 2DGS: 2D Gaussian Splatting for Geometrically Accurate Radiance Fields 2D Gaussian Splatting extends 3D Gaussian Splatting by addressing its limitation in representing mainly volumetric structures but not surfaces. Surfaces are better represented by 2D surfels, which are surface elements defined by: A 2D tangential disk with radius r and a center point. A normal vector pointing outward. Graphics data such as color, texture, and depth. Unlike meshes, surfels do not require connectivity between elements, allowing flexible level-of-detail adaptation: smaller and denser surfels for close-ups, larger and fewer for distant views, balancing quality and computation. Using 2D Gaussian Splatting for 3D Mesh Extraction of the C-arm Machine I chose 2D Gaussian Splatting over the 3D version to extract surface meshes of the C-arm machine. The surfel surfaces were exported as PLY meshes or point clouds. # mesh extraction and video generation python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_172445_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 --unbounded --mesh_res 2048 &amp;&amp; python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_175410_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 --unbounded --mesh_res 2048 python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_173235_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 --unbounded --mesh_res 2048 --render_path python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_173235_20_93\15 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20\15 --unbounded --mesh_res 2048 --render_path Anterior Posterior Medial Lateral The results clearly show the C-arm but with some holes or missing parts in the mesh. Additionally, the scene contains background elements like signposts, since no mask was available to separate the C-arm (foreground) from the background. Manually cleaning is to remove non-C-arm faces and vertices of the mesh. These non-C-arm structure arises because when I perform the mesh extraction, I did not have an image mask to separate the C-arm from the background. It is hard to create such image mask, even though powerful segmentation model such as SAM2 is publicly available. I reckon the segmentation challenges are three-fold: Partial views: SAM2 segmentation model struggles to identify the whole C-arm in close-up images since only portions are visible. Low image resolution: The rendered images used for segmentation are much lower resolution than those SAM2 expects. Non-photorealistic renderings: Generated images sometimes lack photo-realism, limiting segmentation accuracy. Estimating Surface Mesh via TSDF To convert Gaussian splats into a dense volumetric scene, I used the Truncated Signed Distance Function (TSDF). Since, after training, we can render novel views, we use these noisy depth images from RGB rendered images (the camera poses are set according to how we would like to generate the scene). This integration operates on the voxel blocks. Important note: The size of the voxel blocks is critical. If too small relative to the scene, memory usage explodes causing crashes. For my scene, voxel size 0.002 struck a good balance. After volume reconstruction, the mesh is extracted using algorithms like Marching Cubes. Camera Pose Selection A good coverage of camera poses is essential to avoid holes or missing parts in the mesh (such as the base platform of the C-arm or wheels of the cart). Insufficient coverage leads to incomplete geometry recovery. A simpler approach is to use an unbounded camera pose normalization: Normalize the scene into a unit sphere. Uniformly sample cameras on the sphere surface for full coverage. Perform TSDF fusion per voxel block and assemble volumes. Anterior Posterior Medial Lateral Sparse Reconstruction Errors and Consequences Once an erroneous sparse reconstruction is used to train a Gaussian Splatting model, the error manifests itself in an interesting way. Take the above erroneous sparse reconstructed scene as an example, I trained a 2D Gaussian Splatting model and then extracted a mesh from it. The model created an extra phantom C-arm on the back, very interesting results. The misaligned images suggest to the model that there is another phantom arm. What is most intriguing about this result is that in terms of SSIM, PSNR, LPIPS, and reprojection errors, none suggests a huge error exists. That is why Splatvis or visualization is very important - a sure way to verify whether the result makes physical / common sense. Rendered Videos (Novel Views) of C-arm by 2D Gaussian Splatting Finally, this is the part we have been waiting for - rendering the exact same object / C-arm machine but in 100% novel views. To sample this novel camera poses, I defined a new trajectory (circular orbit) and placed cameras evenly. 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation Depth map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Enhanced Quality and Fidelity My valuable lessons, failures and successes are written in Gaussian Splatting - Failure, Success, and Lesson Learned. Equipped with such hindsight, I improved the quality of the Gaussian Splatting outputs. 2D Gaussian Splatting using High Resolution Video of a C-arm Machine to enhance novel view generation Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Normal Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Depth Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Following up next is Gaussian Splatting - Meshes and Beyond Blog posts on this topics Gaussian Splatting - Introduction Gaussian Splatting - Toy Example Gaussian Splatting - Camera Poses Gaussian Splatting - Gaussian Splatting Gaussian Splatting - Meshes and Beyond Gaussian Splatting - Failure, Success, and Lesson Learned" /> <meta property="og:description" content="How to perform Gaussian Splatting? The Gaussian Splatting Python scripts are provided in the original publication - 3D Gaussian Splatting for Real-Time Radiance Field Rendering. To use these scripts, you must first set up the required Python environment. While the setup may seem straightforward, I encountered several challenges during the process that I document here to help others avoid them. The code was first published in 2023, and many dependencies are no longer readily available or compatible with the latest software versions. A common mistake I made was attempting to run it with the most up-to-date packages, which led to numerous incompatibility issues. Hardware Specification GPU: Nvidia GeForce RTX 4070, 8 GB VRAM Driver version: 580.88 CUDA: 11.8 CPU: Intel i7-13620H OS: Windows 11 RAM: 40 GB (Windows page file 60 GB) Python and Package installation I installed both Python 3.8 and 3.10, finding Python 3.10 generally more compatible with most packages since 3.8 is becoming obsolete. Most packages install smoothly as pre-compiled wheels, but some, especially CUDA-related custom modules in Gaussian Splatting, require local compilation. Making sure the compilation tools are of the compatible version with these packages can be tricky. Since most of the time, the authors would not have tested many cases and their success configuration may not be the same as what I have got. After many experiments by trial and error, I have worked out a solution as follows: Microsoft Visual Studio Build Tools 2019 (v143 toolset): Avoid the latest Visual Studio versions like 17.14, which are not backward compatible. Always compile from the VS x64 Native Tools Command Prompt to ensure the correct compiler is called. With this setup, I could follow the official installation guides without issues. Tips and Common Issues Tips: If we use install torch and torch related packages on pip, it is likely that pip install the CPU-only version. So please visit Pytorch official website to get the CUDA-enabled version that is compatible for your device. Watch out for: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized. OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/. Crash and blue-screen Initially, frequent crashes were blamed on Python or the packages. In hindsight, I have figured out the importance and usefulness of windows operating system event report feature. On many occasions, the system crashed due to mis-configured libraries and system settings. Of course, I had no idea at the beginning and mis-attributed the crash due to Python and its packages. After reinstalling Python and its packages, the situation showed no sign of any improvement. I then studied the event report features on windows to get a better understanding on what did occur right before a crash (Windows Event Viewer). The WINDGB tool was very useful because a dump file was generated to record the exact event and all the related programs or dll at that time right after the crash. WINDGB revealed the core issue - multiple CUDA versions installed on the system. I had installed and uninstalled different CUDA versions which corrupted Nvidia dll and caused several errors. Final solution: Thus, the final solution is to update all the graphical drivers and libraries because all evidence pointed to an urgent driver updates (Nvidia and Intel graphic cards). After a CLEAN installation of the latest drivers, the crash had ceased eventually . As for CUDA, keep one and only one version (in this case CUDA 11.8) on the system. Otherwise, python setup may compile the source code against the wrong version. In addition to software upgrades, shutdown all memory intensive programs prior to running Python and increase Windows’ page memory as much as possible. After this step, system stability was restored and crashes stopped. Training 3D Gaussian Splatting # Run 3D AND 2D gaussian splatting train script python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 &amp;&amp; python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 python train.py -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20\15 -m ./outputs/VID_20250725_173235_20_93\15 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 Note: this laptop has limited GPU memory. See computer specification, so the images are downscaled by a multiple of 8. i.e. from 1080x1920 -&gt; 135x240 Results The Gaussian Splatting model was evaluated on a C-arm machine configured in both Anterior-Posterior (AP) and Medial-Lateral (ML) poses. There are two ways to assess the quality: Quantitative metrics: SSIM, PSNR, and LPIPS scores provide numerical evaluation of image quality. Qualitative visualization: Using Splatviz, which allows intuitive inspection of the reconstructions. SSIM, PSNR, LPIPS # evaluation script (evaluation on test images , a total of 53) python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_172445_20_93 python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_175410_20_93 python render.py --iteration 93000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train python metrics.py --model_paths .\outputs\VID_20250725_173235_20_93 Anterior Posterior AP Orientation At iteration 7000 SSIM : 0.9049926 PSNR : 25.9037876 LPIPS: 0.1312765 At iteration 30000 SSIM : 0.9583084 PSNR : 30.5848618 LPIPS: 0.0602733 At iteration 93000 SSIM : 0.9692391 PSNR : 32.1568565 LPIPS: 0.0452350 Medial Lateral Vertical camera frames At iteration 7000 SSIM : 0.9277247 PSNR : 26.7998466 LPIPS: 0.0987048 At iteration 30000 SSIM : 0.9654269 PSNR : 30.7180729 LPIPS: 0.0463373 At iteration 93000 SSIM : 0.9736962 PSNR : 32.5040054 LPIPS: 0.0358106 Horizontal camera frames At iteration 7000 SSIM : 0.8346600 PSNR : 22.8985519 LPIPS: 0.2103405 At iteration 30000 SSIM : 0.9369362 PSNR : 28.4063663 LPIPS: 0.0972803 At iteration 93000 SSIM : 0.9571357 PSNR : 30.3842888 LPIPS: 0.0668879 All in all, the Gaussian Splatting results are very good. Indeed, the more iterations, the better the quality. (albeit the improvement slows drastically) The videos were shot in two different camera orientations. The vertical and the horizontal show very similar end results. I think so long as the video quality is good and the reconstruction is accurate, Gaussian Splatting is quite robust that camera orientation does not matter. Splatviz # Run splat-vis for visualization python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93_previous\point_cloud\iteration_93000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93\point_cloud\iteration_30000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_172445_20_93\point_cloud\iteration_93000 python run_main.py --data_path=C:\Users\hp\tableTop\gs\gaussian-splatting\outputs\VID_20250725_175410_20_93\point_cloud\iteration_93000 Anterior Posterior Medial Lateral Zoom in block to indicate filtering script for Gaussian ellipsoids display filter Gaussian ellipsoids mask = torch.linalg.norm(gs._scaling, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] mask = torch.linalg.norm(gs._opacity, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] 2DGS: 2D Gaussian Splatting for Geometrically Accurate Radiance Fields 2D Gaussian Splatting extends 3D Gaussian Splatting by addressing its limitation in representing mainly volumetric structures but not surfaces. Surfaces are better represented by 2D surfels, which are surface elements defined by: A 2D tangential disk with radius r and a center point. A normal vector pointing outward. Graphics data such as color, texture, and depth. Unlike meshes, surfels do not require connectivity between elements, allowing flexible level-of-detail adaptation: smaller and denser surfels for close-ups, larger and fewer for distant views, balancing quality and computation. Using 2D Gaussian Splatting for 3D Mesh Extraction of the C-arm Machine I chose 2D Gaussian Splatting over the 3D version to extract surface meshes of the C-arm machine. The surfel surfaces were exported as PLY meshes or point clouds. # mesh extraction and video generation python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_172445_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_172445_20 --unbounded --mesh_res 2048 &amp;&amp; python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_175410_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_175410_20 --unbounded --mesh_res 2048 python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_173235_20_93 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20 --unbounded --mesh_res 2048 --render_path python render.py -m C:\Users\hp\tableTop\gs\2d-gaussian-splatting\outputs\VID_20250725_173235_20_93\15 -s C:\Users\hp\tableTop\gs\3dmodeling\data\3dcarm\extracted_frames_VID_20250725_173235_20\15 --unbounded --mesh_res 2048 --render_path Anterior Posterior Medial Lateral The results clearly show the C-arm but with some holes or missing parts in the mesh. Additionally, the scene contains background elements like signposts, since no mask was available to separate the C-arm (foreground) from the background. Manually cleaning is to remove non-C-arm faces and vertices of the mesh. These non-C-arm structure arises because when I perform the mesh extraction, I did not have an image mask to separate the C-arm from the background. It is hard to create such image mask, even though powerful segmentation model such as SAM2 is publicly available. I reckon the segmentation challenges are three-fold: Partial views: SAM2 segmentation model struggles to identify the whole C-arm in close-up images since only portions are visible. Low image resolution: The rendered images used for segmentation are much lower resolution than those SAM2 expects. Non-photorealistic renderings: Generated images sometimes lack photo-realism, limiting segmentation accuracy. Estimating Surface Mesh via TSDF To convert Gaussian splats into a dense volumetric scene, I used the Truncated Signed Distance Function (TSDF). Since, after training, we can render novel views, we use these noisy depth images from RGB rendered images (the camera poses are set according to how we would like to generate the scene). This integration operates on the voxel blocks. Important note: The size of the voxel blocks is critical. If too small relative to the scene, memory usage explodes causing crashes. For my scene, voxel size 0.002 struck a good balance. After volume reconstruction, the mesh is extracted using algorithms like Marching Cubes. Camera Pose Selection A good coverage of camera poses is essential to avoid holes or missing parts in the mesh (such as the base platform of the C-arm or wheels of the cart). Insufficient coverage leads to incomplete geometry recovery. A simpler approach is to use an unbounded camera pose normalization: Normalize the scene into a unit sphere. Uniformly sample cameras on the sphere surface for full coverage. Perform TSDF fusion per voxel block and assemble volumes. Anterior Posterior Medial Lateral Sparse Reconstruction Errors and Consequences Once an erroneous sparse reconstruction is used to train a Gaussian Splatting model, the error manifests itself in an interesting way. Take the above erroneous sparse reconstructed scene as an example, I trained a 2D Gaussian Splatting model and then extracted a mesh from it. The model created an extra phantom C-arm on the back, very interesting results. The misaligned images suggest to the model that there is another phantom arm. What is most intriguing about this result is that in terms of SSIM, PSNR, LPIPS, and reprojection errors, none suggests a huge error exists. That is why Splatvis or visualization is very important - a sure way to verify whether the result makes physical / common sense. Rendered Videos (Novel Views) of C-arm by 2D Gaussian Splatting Finally, this is the part we have been waiting for - rendering the exact same object / C-arm machine but in 100% novel views. To sample this novel camera poses, I defined a new trajectory (circular orbit) and placed cameras evenly. 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation Depth map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Enhanced Quality and Fidelity My valuable lessons, failures and successes are written in Gaussian Splatting - Failure, Success, and Lesson Learned. Equipped with such hindsight, I improved the quality of the Gaussian Splatting outputs. 2D Gaussian Splatting using High Resolution Video of a C-arm Machine to enhance novel view generation Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Normal Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Depth Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Following up next is Gaussian Splatting - Meshes and Beyond Blog posts on this topics Gaussian Splatting - Introduction Gaussian Splatting - Toy Example Gaussian Splatting - Camera Poses Gaussian Splatting - Gaussian Splatting Gaussian Splatting - Meshes and Beyond Gaussian Splatting - Failure, Success, and Lesson Learned" /> <link rel="canonical" href="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" /> <meta property="og:url" content="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" /> <meta property="og:site_name" content="Wilson Fok" /> <meta property="og:image" content="/assets/images/gaussianSplatting/cover.avif" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-08-13T00:00:00+08:00" /> <meta name="twitter:card" content="summary_large_image" /> <meta property="twitter:image" content="/assets/images/gaussianSplatting/cover.avif" /> <meta property="twitter:title" content="Gaussian Splatting - Gaussian Splatting" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Wilson Fok"},"dateModified":"2025-08-13T00:00:00+08:00","datePublished":"2025-08-13T00:00:00+08:00","description":"How to perform Gaussian Splatting? The Gaussian Splatting Python scripts are provided in the original publication - 3D Gaussian Splatting for Real-Time Radiance Field Rendering. To use these scripts, you must first set up the required Python environment. While the setup may seem straightforward, I encountered several challenges during the process that I document here to help others avoid them. The code was first published in 2023, and many dependencies are no longer readily available or compatible with the latest software versions. A common mistake I made was attempting to run it with the most up-to-date packages, which led to numerous incompatibility issues. Hardware Specification GPU: Nvidia GeForce RTX 4070, 8 GB VRAM Driver version: 580.88 CUDA: 11.8 CPU: Intel i7-13620H OS: Windows 11 RAM: 40 GB (Windows page file 60 GB) Python and Package installation I installed both Python 3.8 and 3.10, finding Python 3.10 generally more compatible with most packages since 3.8 is becoming obsolete. Most packages install smoothly as pre-compiled wheels, but some, especially CUDA-related custom modules in Gaussian Splatting, require local compilation. Making sure the compilation tools are of the compatible version with these packages can be tricky. Since most of the time, the authors would not have tested many cases and their success configuration may not be the same as what I have got. After many experiments by trial and error, I have worked out a solution as follows: Microsoft Visual Studio Build Tools 2019 (v143 toolset): Avoid the latest Visual Studio versions like 17.14, which are not backward compatible. Always compile from the VS x64 Native Tools Command Prompt to ensure the correct compiler is called. With this setup, I could follow the official installation guides without issues. Tips and Common Issues Tips: If we use install torch and torch related packages on pip, it is likely that pip install the CPU-only version. So please visit Pytorch official website to get the CUDA-enabled version that is compatible for your device. Watch out for: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized. OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/. Crash and blue-screen Initially, frequent crashes were blamed on Python or the packages. In hindsight, I have figured out the importance and usefulness of windows operating system event report feature. On many occasions, the system crashed due to mis-configured libraries and system settings. Of course, I had no idea at the beginning and mis-attributed the crash due to Python and its packages. After reinstalling Python and its packages, the situation showed no sign of any improvement. I then studied the event report features on windows to get a better understanding on what did occur right before a crash (Windows Event Viewer). The WINDGB tool was very useful because a dump file was generated to record the exact event and all the related programs or dll at that time right after the crash. WINDGB revealed the core issue - multiple CUDA versions installed on the system. I had installed and uninstalled different CUDA versions which corrupted Nvidia dll and caused several errors. Final solution: Thus, the final solution is to update all the graphical drivers and libraries because all evidence pointed to an urgent driver updates (Nvidia and Intel graphic cards). After a CLEAN installation of the latest drivers, the crash had ceased eventually . As for CUDA, keep one and only one version (in this case CUDA 11.8) on the system. Otherwise, python setup may compile the source code against the wrong version. In addition to software upgrades, shutdown all memory intensive programs prior to running Python and increase Windows’ page memory as much as possible. After this step, system stability was restored and crashes stopped. Training 3D Gaussian Splatting # Run 3D AND 2D gaussian splatting train script python train.py -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 &amp;&amp; python train.py -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 python train.py -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20\\15 -m ./outputs/VID_20250725_173235_20_93\\15 --resolution 8 --iterations 93000 --densification_interval 100 --opacity_reset_interval 3000 --densify_from_iter 500 Note: this laptop has limited GPU memory. See computer specification, so the images are downscaled by a multiple of 8. i.e. from 1080x1920 -&gt; 135x240 Results The Gaussian Splatting model was evaluated on a C-arm machine configured in both Anterior-Posterior (AP) and Medial-Lateral (ML) poses. There are two ways to assess the quality: Quantitative metrics: SSIM, PSNR, and LPIPS scores provide numerical evaluation of image quality. Qualitative visualization: Using Splatviz, which allows intuitive inspection of the reconstructions. SSIM, PSNR, LPIPS # evaluation script (evaluation on test images , a total of 53) python render.py --iteration 93000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_172445_20 -m ./outputs/VID_20250725_172445_20_93 --eval --skip_train python metrics.py --model_paths .\\outputs\\VID_20250725_172445_20_93 python render.py --iteration 7000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 30000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python render.py --iteration 93000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_175410_20 -m ./outputs/VID_20250725_175410_20_93 --eval --skip_train python metrics.py --model_paths .\\outputs\\VID_20250725_175410_20_93 python render.py --iteration 93000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 7000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train &amp;&amp; python render.py --iteration 30000 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20 -m ./outputs/VID_20250725_173235_20_93 --eval --skip_train python metrics.py --model_paths .\\outputs\\VID_20250725_173235_20_93 Anterior Posterior AP Orientation At iteration 7000 SSIM : 0.9049926 PSNR : 25.9037876 LPIPS: 0.1312765 At iteration 30000 SSIM : 0.9583084 PSNR : 30.5848618 LPIPS: 0.0602733 At iteration 93000 SSIM : 0.9692391 PSNR : 32.1568565 LPIPS: 0.0452350 Medial Lateral Vertical camera frames At iteration 7000 SSIM : 0.9277247 PSNR : 26.7998466 LPIPS: 0.0987048 At iteration 30000 SSIM : 0.9654269 PSNR : 30.7180729 LPIPS: 0.0463373 At iteration 93000 SSIM : 0.9736962 PSNR : 32.5040054 LPIPS: 0.0358106 Horizontal camera frames At iteration 7000 SSIM : 0.8346600 PSNR : 22.8985519 LPIPS: 0.2103405 At iteration 30000 SSIM : 0.9369362 PSNR : 28.4063663 LPIPS: 0.0972803 At iteration 93000 SSIM : 0.9571357 PSNR : 30.3842888 LPIPS: 0.0668879 All in all, the Gaussian Splatting results are very good. Indeed, the more iterations, the better the quality. (albeit the improvement slows drastically) The videos were shot in two different camera orientations. The vertical and the horizontal show very similar end results. I think so long as the video quality is good and the reconstruction is accurate, Gaussian Splatting is quite robust that camera orientation does not matter. Splatviz # Run splat-vis for visualization python run_main.py --data_path=C:\\Users\\hp\\tableTop\\gs\\gaussian-splatting\\outputs\\VID_20250725_172445_20_93_previous\\point_cloud\\iteration_93000 python run_main.py --data_path=C:\\Users\\hp\\tableTop\\gs\\gaussian-splatting\\outputs\\VID_20250725_172445_20_93\\point_cloud\\iteration_30000 python run_main.py --data_path=C:\\Users\\hp\\tableTop\\gs\\gaussian-splatting\\outputs\\VID_20250725_172445_20_93\\point_cloud\\iteration_93000 python run_main.py --data_path=C:\\Users\\hp\\tableTop\\gs\\gaussian-splatting\\outputs\\VID_20250725_175410_20_93\\point_cloud\\iteration_93000 Anterior Posterior Medial Lateral Zoom in block to indicate filtering script for Gaussian ellipsoids display filter Gaussian ellipsoids mask = torch.linalg.norm(gs._scaling, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] mask = torch.linalg.norm(gs._opacity, dim=-1) &lt; slider.x gs._xyz = gs._xyz[mask] gs._rotation = gs._rotation[mask] gs._scaling = gs._scaling[mask] gs._opacity = gs._opacity[mask] gs._features_dc = gs._features_dc[mask] gs._features_rest = gs._features_rest[mask] 2DGS: 2D Gaussian Splatting for Geometrically Accurate Radiance Fields 2D Gaussian Splatting extends 3D Gaussian Splatting by addressing its limitation in representing mainly volumetric structures but not surfaces. Surfaces are better represented by 2D surfels, which are surface elements defined by: A 2D tangential disk with radius r and a center point. A normal vector pointing outward. Graphics data such as color, texture, and depth. Unlike meshes, surfels do not require connectivity between elements, allowing flexible level-of-detail adaptation: smaller and denser surfels for close-ups, larger and fewer for distant views, balancing quality and computation. Using 2D Gaussian Splatting for 3D Mesh Extraction of the C-arm Machine I chose 2D Gaussian Splatting over the 3D version to extract surface meshes of the C-arm machine. The surfel surfaces were exported as PLY meshes or point clouds. # mesh extraction and video generation python render.py -m C:\\Users\\hp\\tableTop\\gs\\2d-gaussian-splatting\\outputs\\VID_20250725_172445_20_93 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_172445_20 --unbounded --mesh_res 2048 &amp;&amp; python render.py -m C:\\Users\\hp\\tableTop\\gs\\2d-gaussian-splatting\\outputs\\VID_20250725_175410_20_93 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_175410_20 --unbounded --mesh_res 2048 python render.py -m C:\\Users\\hp\\tableTop\\gs\\2d-gaussian-splatting\\outputs\\VID_20250725_173235_20_93 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20 --unbounded --mesh_res 2048 --render_path python render.py -m C:\\Users\\hp\\tableTop\\gs\\2d-gaussian-splatting\\outputs\\VID_20250725_173235_20_93\\15 -s C:\\Users\\hp\\tableTop\\gs\\3dmodeling\\data\\3dcarm\\extracted_frames_VID_20250725_173235_20\\15 --unbounded --mesh_res 2048 --render_path Anterior Posterior Medial Lateral The results clearly show the C-arm but with some holes or missing parts in the mesh. Additionally, the scene contains background elements like signposts, since no mask was available to separate the C-arm (foreground) from the background. Manually cleaning is to remove non-C-arm faces and vertices of the mesh. These non-C-arm structure arises because when I perform the mesh extraction, I did not have an image mask to separate the C-arm from the background. It is hard to create such image mask, even though powerful segmentation model such as SAM2 is publicly available. I reckon the segmentation challenges are three-fold: Partial views: SAM2 segmentation model struggles to identify the whole C-arm in close-up images since only portions are visible. Low image resolution: The rendered images used for segmentation are much lower resolution than those SAM2 expects. Non-photorealistic renderings: Generated images sometimes lack photo-realism, limiting segmentation accuracy. Estimating Surface Mesh via TSDF To convert Gaussian splats into a dense volumetric scene, I used the Truncated Signed Distance Function (TSDF). Since, after training, we can render novel views, we use these noisy depth images from RGB rendered images (the camera poses are set according to how we would like to generate the scene). This integration operates on the voxel blocks. Important note: The size of the voxel blocks is critical. If too small relative to the scene, memory usage explodes causing crashes. For my scene, voxel size 0.002 struck a good balance. After volume reconstruction, the mesh is extracted using algorithms like Marching Cubes. Camera Pose Selection A good coverage of camera poses is essential to avoid holes or missing parts in the mesh (such as the base platform of the C-arm or wheels of the cart). Insufficient coverage leads to incomplete geometry recovery. A simpler approach is to use an unbounded camera pose normalization: Normalize the scene into a unit sphere. Uniformly sample cameras on the sphere surface for full coverage. Perform TSDF fusion per voxel block and assemble volumes. Anterior Posterior Medial Lateral Sparse Reconstruction Errors and Consequences Once an erroneous sparse reconstruction is used to train a Gaussian Splatting model, the error manifests itself in an interesting way. Take the above erroneous sparse reconstructed scene as an example, I trained a 2D Gaussian Splatting model and then extracted a mesh from it. The model created an extra phantom C-arm on the back, very interesting results. The misaligned images suggest to the model that there is another phantom arm. What is most intriguing about this result is that in terms of SSIM, PSNR, LPIPS, and reprojection errors, none suggests a huge error exists. That is why Splatvis or visualization is very important - a sure way to verify whether the result makes physical / common sense. Rendered Videos (Novel Views) of C-arm by 2D Gaussian Splatting Finally, this is the part we have been waiting for - rendering the exact same object / C-arm machine but in 100% novel views. To sample this novel camera poses, I defined a new trajectory (circular orbit) and placed cameras evenly. 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation Depth map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation Enhanced Quality and Fidelity My valuable lessons, failures and successes are written in Gaussian Splatting - Failure, Success, and Lesson Learned. Equipped with such hindsight, I improved the quality of the Gaussian Splatting outputs. 2D Gaussian Splatting using High Resolution Video of a C-arm Machine to enhance novel view generation Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Normal Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Depth Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone Following up next is Gaussian Splatting - Meshes and Beyond Blog posts on this topics Gaussian Splatting - Introduction Gaussian Splatting - Toy Example Gaussian Splatting - Camera Poses Gaussian Splatting - Gaussian Splatting Gaussian Splatting - Meshes and Beyond Gaussian Splatting - Failure, Success, and Lesson Learned","headline":"Gaussian Splatting - Gaussian Splatting","image":"/assets/images/gaussianSplatting/cover.avif","mainEntityOfPage":{"@type":"WebPage","@id":"/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/"},"url":"/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/"}</script> <!-- End Jekyll SEO tag --> <title>Wilson Fok - A data science enthusiast</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Gaussian Splatting - Gaussian Splatting" /> <meta name="keywords" content="Gaussian Splatting - Gaussian Splatting, Wilson Fok, Deep_Learning" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Wilson Fok" property="og:site_name"> <meta content="Gaussian Splatting - Gaussian Splatting" property="og:title"> <meta content="article" property="og:type"> <meta content="This series of articles explores Gaussian Splatting and Neural Radiance Fields (NeRF) for 3D scene reconstruction using C-arm X-ray machine videos. It details capturing video, extracting frames, sparse reconstruction with COLMAP, and training Gaussian Splatting models for real-time, photorealistic 3D rendering. The author shares practical setup challenges, evaluation metrics (SSIM, PSNR, LPIPS), visualization with Splatviz, and mesh extraction for use in Blender and Unity." property="og:description"> <meta content="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" property="og:url"> <meta content="2025-08-13T00:00:00+08:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="/assets/img/posts//assets/images/gaussianSplatting/cover.avif" property="og:image"> <meta content="Deep_Learning" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="Gaussian Splatting - Gaussian Splatting"> <meta content="Wilson Fok" property="og:site_name"> <meta name="twitter:url" content="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/"> <meta name="twitter:description" content="Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. I also like to make new friends and connections. Let's connect! "> <!-- load layout style css --> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <!-- one or more of the below scripts does fancy word animation and dropdown menu --> <script src="/assets/extra_js/jquery-3.4.1.min.js"></script> <script src="/assets/extra_js/picturefill min/picturefill.min.js"></script> <script src="/assets/extra_js/instantsearch min/instantsearch.min.js"></script> <script src="/assets/extra_js/moment min/moment.min.js"></script> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </head><body> <div class="container-fluid"><header> <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script> <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css"> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Wilson Fok</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Wilson Fok</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog/categories">Categories</a> </li> <li class="nav-item"> <a class="nav-link" href="/gallery">Gallery</a> </li> <li class="nav-item"> <a class="nav-link" href="/contact">Contact Me</a> </li> </ul> </div> <ul class="nav justify-content-end"> <!-- <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> --> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/">Gaussian Splatting - Gaussian Splatting</a></li> </ol> </nav> </div><div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <h1 class="post-title" itemprop="name headline">Gaussian Splatting - Gaussian Splatting</h1> <p></p> <h6 class="post-meta"> <i> Summary : This series of articles explores Gaussian Splatting and Neural Radiance Fields (NeRF) for 3D scene reconstruction using C-arm X-ray machine videos. It details capturing video, extracting frames, sparse reconstruction with COLMAP, and training Gaussian Splatting models for real-time, photorealistic 3D rendering. The author shares practical setup challenges, evaluation metrics (SSIM, PSNR, LPIPS), visualization with Splatviz, and mesh extraction for use in Blender and Unity.</i> </h6> <p class="post-summary">Posted by : <img src="/assets/img/profile.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Wilson Fok</span> </span> on <time datetime="2025-08-13 00:00:00 +0800" itemprop="datePublished">Aug 13, 2025</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/"></span> <div class="post-categories"> Category : <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </div> </div> <div class="card-body" itemprop="articleBody"> <h1 id="how-to-perform-gaussian-splatting">How to perform Gaussian Splatting?</h1> <p>The Gaussian Splatting Python scripts are provided in the original publication - <a href="https://github.com/graphdeco-inria/gaussian-splatting">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>. To use these scripts, you must first set up the required Python environment. While the setup may seem straightforward, I encountered several challenges during the process that I document here to help others avoid them.</p> <p>The code was first published in 2023, and many dependencies are no longer readily available or compatible with the latest software versions. A common mistake I made was attempting to run it with the most up-to-date packages, which led to numerous incompatibility issues.</p> <h3 id="hardware-specification">Hardware Specification</h3> <ul> <li><strong>GPU:</strong> Nvidia GeForce RTX 4070, 8 GB VRAM</li> <li><strong>Driver version:</strong> 580.88</li> <li><strong>CUDA:</strong> 11.8</li> <li><strong>CPU:</strong> Intel i7-13620H</li> <li><strong>OS:</strong> Windows 11</li> <li><strong>RAM:</strong> 40 GB (Windows page file 60 GB)</li> </ul> <h3 id="python-and-package-installation">Python and Package installation</h3> <p>I installed both Python 3.8 and 3.10, finding Python 3.10 generally more compatible with most packages since 3.8 is becoming obsolete. Most packages install smoothly as pre-compiled wheels, but some, especially CUDA-related custom modules in Gaussian Splatting, require local compilation.</p> <p>Making sure the compilation tools are of the compatible version with these packages can be tricky. Since most of the time, the authors would not have tested many cases and their success configuration may not be the same as what I have got. After many experiments by trial and error, I have worked out a solution as follows:</p> <ul> <li><strong>Microsoft Visual Studio Build Tools 2019 (v143 toolset):</strong><br /> Avoid the latest Visual Studio versions like 17.14, which are not backward compatible.</li> <li>Always compile from the <strong>VS x64 Native Tools Command Prompt</strong> to ensure the correct compiler is called.</li> </ul> <p>With this setup, I could follow the official installation guides without issues.</p> <h3 id="tips-and-common-issues">Tips and Common Issues</h3> <p>Tips: If we use install torch and torch related packages on pip, it is likely that pip install the CPU-only version. So please visit <a href="https://pytorch.org/get-started/previous-versions">Pytorch official website</a> to get the CUDA-enabled version that is compatible for your device.</p> <p>Watch out for: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized. OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.</p> <h3 id="crash-and-blue-screen">Crash and blue-screen</h3> <p>Initially, frequent crashes were blamed on Python or the packages. In hindsight, I have figured out the importance and usefulness of windows operating system event report feature. On many occasions, the system crashed due to mis-configured libraries and system settings. Of course, I had no idea at the beginning and mis-attributed the crash due to Python and its packages. After reinstalling Python and its packages, the situation showed no sign of any improvement. I then studied the event report features on windows to get a better understanding on what did occur right before a crash (Windows Event Viewer). The WINDGB tool was very useful because a dump file was generated to record the exact event and all the related programs or dll at that time right after the crash. WINDGB revealed the core issue - multiple CUDA versions installed on the system. I had installed and uninstalled different CUDA versions which corrupted Nvidia dll and caused several errors.</p> <p><strong>Final solution:</strong> Thus, the final solution is to update all the graphical drivers and libraries because all evidence pointed to an urgent driver updates (Nvidia and Intel graphic cards). After a CLEAN installation of the latest drivers, the crash had ceased eventually . As for CUDA, keep one and only one version (in this case CUDA 11.8) on the system. Otherwise, python setup may compile the source code against the wrong version.</p> <p>In addition to software upgrades, shutdown all memory intensive programs prior to running Python and increase Windows’ page memory as much as possible.</p> <p>After this step, system stability was restored and crashes stopped.</p> <h3 id="training-3d-gaussian-splatting">Training 3D Gaussian Splatting</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Run 3D AND 2D gaussian splatting train script
</span><span class="n">python</span> <span class="n">train</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_172445_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_172445_20_93</span> <span class="o">--</span><span class="n">resolution</span> <span class="mi">8</span> <span class="o">--</span><span class="n">iterations</span> <span class="mi">93000</span> <span class="o">--</span><span class="n">densification_interval</span> <span class="mi">100</span> <span class="o">--</span><span class="n">opacity_reset_interval</span> <span class="mi">3000</span> <span class="o">--</span><span class="n">densify_from_iter</span> <span class="mi">500</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">train</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_175410_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_175410_20_93</span> <span class="o">--</span><span class="n">resolution</span> <span class="mi">8</span> <span class="o">--</span><span class="n">iterations</span> <span class="mi">93000</span> <span class="o">--</span><span class="n">densification_interval</span> <span class="mi">100</span> <span class="o">--</span><span class="n">opacity_reset_interval</span> <span class="mi">3000</span> <span class="o">--</span><span class="n">densify_from_iter</span> <span class="mi">500</span>


<span class="n">python</span> <span class="n">train</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span>\<span class="mi">15</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_173235_20_93</span>\<span class="mi">15</span> <span class="o">--</span><span class="n">resolution</span> <span class="mi">8</span> <span class="o">--</span><span class="n">iterations</span> <span class="mi">93000</span> <span class="o">--</span><span class="n">densification_interval</span> <span class="mi">100</span> <span class="o">--</span><span class="n">opacity_reset_interval</span> <span class="mi">3000</span> <span class="o">--</span><span class="n">densify_from_iter</span> <span class="mi">500</span>




<span class="n">Note</span><span class="p">:</span> <span class="n">this</span> <span class="n">laptop</span> <span class="n">has</span> <span class="n">limited</span> <span class="n">GPU</span> <span class="n">memory</span><span class="p">.</span> <span class="n">See</span> <span class="n">computer</span> <span class="n">specification</span><span class="p">,</span> <span class="n">so</span> <span class="n">the</span> <span class="n">images</span> <span class="n">are</span> <span class="n">downscaled</span> <span class="n">by</span> <span class="n">a</span> <span class="n">multiple</span> <span class="n">of</span> <span class="mf">8.</span> <span class="n">i</span><span class="p">.</span><span class="n">e</span><span class="p">.</span> <span class="k">from</span> <span class="mi">1080</span><span class="n">x1920</span> <span class="o">-&gt;</span> <span class="mi">135</span><span class="n">x240</span>




</code></pre></div></div> <h2 id="results">Results</h2> <p>The Gaussian Splatting model was evaluated on a C-arm machine configured in both Anterior-Posterior (AP) and Medial-Lateral (ML) poses.</p> <p>There are two ways to assess the quality:</p> <ol> <li><strong>Quantitative metrics</strong>: SSIM, PSNR, and LPIPS scores provide numerical evaluation of image quality.</li> <li><strong>Qualitative visualization</strong>: Using <a href="https://github.com/Florian-Barthel/splatviz">Splatviz</a>, which allows intuitive inspection of the reconstructions.</li> </ol> <h2 id="ssim-psnr-lpips">SSIM, PSNR, LPIPS</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># evaluation script (evaluation on test images , a total of 53)
</span>
<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">93000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_172445_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_172445_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">7000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_172445_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_172445_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">30000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_172445_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_172445_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span>

<span class="n">python</span> <span class="n">metrics</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_paths</span> <span class="p">.</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_172445_20_93</span>

<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">7000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_175410_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_175410_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span>
<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">30000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_175410_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_175410_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span>
<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">93000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_175410_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_175410_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span>

<span class="n">python</span> <span class="n">metrics</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_paths</span> <span class="p">.</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_175410_20_93</span>

<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">93000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_173235_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">7000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_173235_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">iteration</span> <span class="mi">30000</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span> <span class="o">-</span><span class="n">m</span> <span class="p">.</span><span class="o">/</span><span class="n">outputs</span><span class="o">/</span><span class="n">VID_20250725_173235_20_93</span> <span class="o">--</span><span class="nb">eval</span> <span class="o">--</span><span class="n">skip_train</span>

<span class="n">python</span> <span class="n">metrics</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_paths</span> <span class="p">.</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_173235_20_93</span>

</code></pre></div></div> <h3 id="anterior-posterior">Anterior Posterior</h3> <p><strong>AP Orientation</strong></p> <p>At iteration 7000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9049926
PSNR :   25.9037876
LPIPS:    0.1312765
</code></pre></div></div> <p>At iteration 30000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9583084
PSNR :   30.5848618
LPIPS:    0.0602733
</code></pre></div></div> <p>At iteration 93000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9692391
PSNR :   32.1568565
LPIPS:    0.0452350
</code></pre></div></div> <h3 id="medial-lateral">Medial Lateral</h3> <p><em>Vertical camera frames</em></p> <p>At iteration 7000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9277247
PSNR :   26.7998466
LPIPS:    0.0987048
</code></pre></div></div> <p>At iteration 30000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9654269
PSNR :   30.7180729
LPIPS:    0.0463373
</code></pre></div></div> <p>At iteration 93000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9736962
PSNR :   32.5040054
LPIPS:    0.0358106
</code></pre></div></div> <p><em>Horizontal camera frames</em></p> <p>At iteration 7000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.8346600
PSNR :   22.8985519
LPIPS:    0.2103405
</code></pre></div></div> <p>At iteration 30000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9369362
PSNR :   28.4063663
LPIPS:    0.0972803
</code></pre></div></div> <p>At iteration 93000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SSIM :    0.9571357
PSNR :   30.3842888
LPIPS:    0.0668879
</code></pre></div></div> <p>All in all, the Gaussian Splatting results are very good. Indeed, the more iterations, the better the quality. (albeit the improvement slows drastically)</p> <p>The videos were shot in two different camera orientations. The vertical and the horizontal show very similar end results. I think so long as the video quality is good and the reconstruction is accurate, Gaussian Splatting is quite robust that camera orientation does not matter.</p> <h1 id="splatviz">Splatviz</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Run splat-vis for visualization
</span>
<span class="n">python</span> <span class="n">run_main</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span><span class="o">=</span><span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_172445_20_93_previous</span>\<span class="n">point_cloud</span>\<span class="n">iteration_93000</span>
<span class="n">python</span> <span class="n">run_main</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span><span class="o">=</span><span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_172445_20_93</span>\<span class="n">point_cloud</span>\<span class="n">iteration_30000</span>


<span class="n">python</span> <span class="n">run_main</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span><span class="o">=</span><span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_172445_20_93</span>\<span class="n">point_cloud</span>\<span class="n">iteration_93000</span>
<span class="n">python</span> <span class="n">run_main</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span><span class="o">=</span><span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_175410_20_93</span>\<span class="n">point_cloud</span>\<span class="n">iteration_93000</span>

</code></pre></div></div> <h3 id="anterior-posterior-1">Anterior Posterior</h3> <p><img src="/assets/images/gaussianSplatting/ap_splatvis.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <h3 id="medial-lateral-1">Medial Lateral</h3> <p><img src="/assets/images/gaussianSplatting/ml_splatvis.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p>Zoom in block to indicate filtering script for Gaussian ellipsoids display</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">filter</span> <span class="n">Gaussian</span> <span class="n">ellipsoids</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">gs</span><span class="p">.</span><span class="n">_scaling</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">slider</span><span class="p">.</span><span class="n">x</span>

<span class="n">gs</span><span class="p">.</span><span class="n">_xyz</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_xyz</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_rotation</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_rotation</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_scaling</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_scaling</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_opacity</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_opacity</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_features_dc</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_features_dc</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_features_rest</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_features_rest</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>


<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">gs</span><span class="p">.</span><span class="n">_opacity</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">slider</span><span class="p">.</span><span class="n">x</span>

<span class="n">gs</span><span class="p">.</span><span class="n">_xyz</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_xyz</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_rotation</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_rotation</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_scaling</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_scaling</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_opacity</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_opacity</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_features_dc</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_features_dc</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">gs</span><span class="p">.</span><span class="n">_features_rest</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">_features_rest</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
</code></pre></div></div> <h1 id="2dgs-2d-gaussian-splatting-for-geometrically-accurate-radiance-fields">2DGS: 2D Gaussian Splatting for Geometrically Accurate Radiance Fields</h1> <p><a href="https://surfsplatting.github.io/">2D Gaussian Splatting</a> extends 3D Gaussian Splatting by addressing its limitation in representing mainly volumetric structures but not surfaces. Surfaces are better represented by <strong>2D surfels</strong>, which are surface elements defined by:</p> <ul> <li>A 2D tangential disk with radius <em>r</em> and a center point.</li> <li>A normal vector pointing outward.</li> <li>Graphics data such as color, texture, and depth.</li> </ul> <p>Unlike meshes, surfels do not require connectivity between elements, allowing flexible level-of-detail adaptation: smaller and denser surfels for close-ups, larger and fewer for distant views, balancing quality and computation.</p> <h3 id="using-2d-gaussian-splatting-for-3d-mesh-extraction-of-the-c-arm-machine">Using 2D Gaussian Splatting for 3D Mesh Extraction of the C-arm Machine</h3> <p>I chose 2D Gaussian Splatting over the 3D version to extract surface meshes of the C-arm machine. The surfel surfaces were exported as PLY meshes or point clouds.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># mesh extraction and video generation
</span>
<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">m</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">2</span><span class="n">d</span><span class="o">-</span><span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_172445_20_93</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_172445_20</span> <span class="o">--</span><span class="n">unbounded</span> <span class="o">--</span><span class="n">mesh_res</span> <span class="mi">2048</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">m</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">2</span><span class="n">d</span><span class="o">-</span><span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_175410_20_93</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_175410_20</span> <span class="o">--</span><span class="n">unbounded</span> <span class="o">--</span><span class="n">mesh_res</span> <span class="mi">2048</span>

<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">m</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">2</span><span class="n">d</span><span class="o">-</span><span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_173235_20_93</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span> <span class="o">--</span><span class="n">unbounded</span> <span class="o">--</span><span class="n">mesh_res</span> <span class="mi">2048</span> <span class="o">--</span><span class="n">render_path</span>
<span class="n">python</span> <span class="n">render</span><span class="p">.</span><span class="n">py</span> <span class="o">-</span><span class="n">m</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">2</span><span class="n">d</span><span class="o">-</span><span class="n">gaussian</span><span class="o">-</span><span class="n">splatting</span>\<span class="n">outputs</span>\<span class="n">VID_20250725_173235_20_93</span>\<span class="mi">15</span> <span class="o">-</span><span class="n">s</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">hp</span>\<span class="n">tableTop</span>\<span class="n">gs</span>\<span class="mi">3</span><span class="n">dmodeling</span>\<span class="n">data</span>\<span class="mi">3</span><span class="n">dcarm</span>\<span class="n">extracted_frames_VID_20250725_173235_20</span>\<span class="mi">15</span> <span class="o">--</span><span class="n">unbounded</span> <span class="o">--</span><span class="n">mesh_res</span> <span class="mi">2048</span> <span class="o">--</span><span class="n">render_path</span>



</code></pre></div></div> <h3 id="anterior-posterior-2">Anterior Posterior</h3> <p><img src="/assets/images/gaussianSplatting/snapshot02.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <h3 id="medial-lateral-2">Medial Lateral</h3> <p><img src="/assets/images/gaussianSplatting/snapshot03.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p>The results clearly show the C-arm but with some <strong>holes or missing parts</strong> in the mesh. Additionally, the scene contains background elements like signposts, since no mask was available to separate the C-arm (foreground) from the background.</p> <p><em>Manually cleaning</em> is to remove non-C-arm faces and vertices of the mesh. These non-C-arm structure arises because when I perform the mesh extraction, I did not have an image mask to separate the C-arm from the background. It is hard to create such image mask, even though powerful segmentation model such as SAM2 is publicly available.</p> <p>I reckon the segmentation challenges are three-fold:</p> <ol> <li><strong>Partial views:</strong> SAM2 segmentation model struggles to identify the whole C-arm in close-up images since only portions are visible.</li> <li><strong>Low image resolution:</strong> The rendered images used for segmentation are much lower resolution than those SAM2 expects.</li> <li><strong>Non-photorealistic renderings:</strong> Generated images sometimes lack photo-realism, limiting segmentation accuracy.</li> </ol> <h3 id="estimating-surface-mesh-via-tsdf">Estimating Surface Mesh via TSDF</h3> <p>To convert Gaussian splats into a dense volumetric scene, I used the <strong>Truncated Signed Distance Function (TSDF)</strong>. Since, after training, we can render novel views, we use these noisy depth images from RGB rendered images (the camera poses are set according to how we would like to generate the scene). This integration operates on the voxel blocks.</p> <p><strong>Important note:</strong> The size of the voxel blocks is critical. If too small relative to the scene, memory usage explodes causing crashes. For my scene, voxel size 0.002 struck a good balance. After volume reconstruction, the mesh is extracted using algorithms like Marching Cubes.</p> <h3 id="camera-pose-selection">Camera Pose Selection</h3> <p>A good coverage of camera poses is essential to avoid holes or missing parts in the mesh (such as the base platform of the C-arm or wheels of the cart). Insufficient coverage leads to incomplete geometry recovery.</p> <p>A simpler approach is to use an <strong>unbounded camera pose normalization</strong>:</p> <ul> <li>Normalize the scene into a unit sphere.</li> <li>Uniformly sample cameras on the sphere surface for full coverage.</li> <li>Perform TSDF fusion per voxel block and assemble volumes.</li> </ul> <h3 id="anterior-posterior-3">Anterior Posterior</h3> <p><img src="/assets/images/gaussianSplatting/snapshot10.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p><img src="/assets/images/gaussianSplatting/snapshot11.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <h3 id="medial-lateral-3">Medial Lateral</h3> <p><img src="/assets/images/gaussianSplatting/snapshot23.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p><img src="/assets/images/gaussianSplatting/snapshot24.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <h4 id="sparse-reconstruction-errors-and-consequences">Sparse Reconstruction Errors and Consequences</h4> <p>Once an erroneous sparse reconstruction is used to train a Gaussian Splatting model, the error manifests itself in an interesting way.</p> <p>Take the above erroneous sparse reconstructed scene as an example, I trained a 2D Gaussian Splatting model and then extracted a mesh from it.</p> <p><img src="/assets/images/gaussianSplatting/snapshot101.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p><img src="/assets/images/gaussianSplatting/snapshot102.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;" /></p> <p>The model created an extra phantom C-arm on the back, very interesting results. The misaligned images suggest to the model that there is another phantom arm.</p> <p>What is most intriguing about this result is that in terms of SSIM, PSNR, LPIPS, and reprojection errors, none suggests a huge error exists. That is why Splatvis or visualization is very important - a sure way to verify whether the result makes physical / common sense.</p> <h3 id="rendered-videos-novel-views-of-c-arm-by-2d-gaussian-splatting">Rendered Videos (Novel Views) of C-arm by 2D Gaussian Splatting</h3> <p>Finally, this is the part we have been waiting for - rendering the exact same object / C-arm machine but in 100% novel views. To sample this novel camera poses, I defined a new trajectory (circular orbit) and placed cameras evenly.</p> <p><em>2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/RhODF_o-eU4?si=kk3ww7NSOUI3f2X-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>Depth Map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in ML Orientation</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/-IZ77YHK8QE?si=XP3jDqgyOtv5IP1j" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/xoZIMdK2QMQ?si=-TUUG5N4xy2dfaKF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>Depth map: 2D Gaussian Splatting (Horizontal Camera filming) of a C-arm Machine in AP Orientation</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/2DP5MfRsnsc?si=WjOjQwrvJNHRLKxC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation</em></p> <iframe width="315" height="560" src="https://youtube.com/embed/SL8tMtM7qmE?si=LaBN9O6JcfqG8SOo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <p><em>Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in ML Orientation</em></p> <iframe width="315" height="560" src="https://youtube.com/embed/Yp4pH535woE?si=H9zSRYjU_LHRTBI4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <p><em>2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation</em></p> <iframe width="315" height="560" src="https://youtube.com/embed/b-Aqys3IJ5g?si=VxYkoxdsmi4lYGZE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <p><em>Depth Map: 2D Gaussian Splatting (Vertical Camera filming) of a C-arm Machine in AP Orientation</em></p> <iframe width="315" height="560" src="https://youtube.com/embed/Z7Nb8JbVnww?si=gytWXq0Hsu-4mNd5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <h1 id="enhanced-quality-and-fidelity">Enhanced Quality and Fidelity</h1> <p>My valuable lessons, failures and successes are written in <a href="/deep_learning/2025/08/19/GaussianSplatting_failuresAndLessons/">Gaussian Splatting - Failure, Success, and Lesson Learned</a>. Equipped with such hindsight, I improved the quality of the Gaussian Splatting outputs.</p> <p>2D Gaussian Splatting using High Resolution Video of a C-arm Machine to enhance novel view generation</p> <p><em>Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/96a9EQ8jIII?si=K7SJLJhk0fOmvo0G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>Normal Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/cojZnJmjBWM?si=L-NuXUTzEMokS8uP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p><em>Depth Map - Gaussian Splatting: High Resolution C-arm Video to Enhance Novel View Generation from Smartphone</em></p> <iframe width="560" height="315" src="https://www.youtube.com/embed/Vl4DalN8W3M?si=_-taM6jKx1WXmoyt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <p>Following up next is <a href="/deep_learning/2025/08/14/GaussianSplatting_meshesAndBeyond/">Gaussian Splatting - Meshes and Beyond</a></p> <h1 id="blog-posts-on-this-topics">Blog posts on this topics</h1> <ul> <li><a href="/deep_learning/2025/08/10/GaussianSplatting_introduction/">Gaussian Splatting - Introduction</a></li> <li><a href="/deep_learning/2025/08/11/GaussianSplatting_toyExample/">Gaussian Splatting - Toy Example</a></li> <li><a href="/deep_learning/2025/08/12/GaussianSplatting_camera_poses/">Gaussian Splatting - Camera Poses</a></li> <li><a href="/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/">Gaussian Splatting - Gaussian Splatting</a></li> <li><a href="/deep_learning/2025/08/14/GaussianSplatting_meshesAndBeyond/">Gaussian Splatting - Meshes and Beyond</a></li> <li><a href="/deep_learning/2025/08/19/GaussianSplatting_failuresAndLessons/">Gaussian Splatting - Failure, Success, and Lesson Learned</a></li> </ul> </div> <div id="disqus_thread"></div> </article> <article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-body" itemprop="articleBody"> <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> <div class="card-header"> <span class="title"> <i class="fa fa-share"></i> Share this to: </span> </div> <div id="share-bar"> <div class="share-buttons"> <a href="https://www.facebook.com/sharer/sharer.php?u=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook" > <i class="fa fa-facebook-official share-button"> facebook</i> </a> <a href="https://twitter.com/intent/tweet?text=Gaussian Splatting - Gaussian Splatting&url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter" > <i class="fa fa-twitter share-button"> twitter</i> </a> <a href="https://plus.google.com/share?url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Google+" > <i class="fa fa-google-plus share-button"> google</i> </a> <a href="https://www.pinterest.com/pin/create/button/?url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Pinterest" > <i class="fa fa-pinterest-p share-button"> pinterest</i> </a> <a href="https://www.tumblr.com/share/link?url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Tumblr" > <i class="fa fa-tumblr share-button"> tumblr</i> </a> <a href="http://www.reddit.com/submit?url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" title="Share on Reddit" > <i class="fa fa-reddit-alien share-button"> reddit</i> </a> <a href="https://www.linkedin.com/shareArticle?mini=true&url=/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/&title=Gaussian Splatting - Gaussian Splatting&summary=&source=Wilson Fok" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn" > <i class="fa fa-linkedin share-button"> linkedin</i> </a> <a href="mailto:?subject=Gaussian Splatting - Gaussian Splatting&amp;body=Check out this site /deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/" title="Share via Email" > <i class="fa fa-envelope share-button"> email</i> </a> </div> </div> </div> </article> <script> var disqus_config = function () { this.page.url = "/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/deep_learning/2025/08/13/GaussianSplatting_gaussianSplatting"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My name is Wilson Fok. I love to extract useful insights and knowledge from big data. Constructive feedback and insightful comments are very welcome!</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#Finance"></div> <li class="tag-head"> <a href="/blog/categories/Finance">Finance</a> </li> <a name="Finance"></a> <div id="#NLP"></div> <li class="tag-head"> <a href="/blog/categories/NLP">NLP</a> </li> <a name="NLP"></a> <div id="#Deep_Learning"></div> <li class="tag-head"> <a href="/blog/categories/Deep_Learning">Deep_Learning</a> </li> <a name="Deep_Learning"></a> <div id="#Others"></div> <li class="tag-head"> <a href="/blog/categories/Others">Others</a> </li> <a name="Others"></a> <div id="#Reading"></div> <li class="tag-head"> <a href="/blog/categories/Reading">Reading</a> </li> <a name="Reading"></a> <div id="#Toastmasters"></div> <li class="tag-head"> <a href="/blog/categories/Toastmasters">Toastmasters</a> </li> <a name="Toastmasters"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> <li > <a href="/blog/categories">Categories</a> </li> <li > <a href="/gallery">Gallery</a> </li> <li > <a href="/contact">Contact Me</a> </li> </div> </div> </div> </div> </div> <footer> <p> Powered by Jekyll. Hosted on <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS <i class="fa fa-rss" aria-hidden="true"></i> </a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <!-- <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> --> <script src="/assets/js/mode-switcher.js"></script> <script src="/assets/js/slideshow.js"></script> </body> </html>
